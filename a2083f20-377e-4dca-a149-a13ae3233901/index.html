<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="My personal digital garden"><meta name=author content=Sean><link href=https://Joon-Park92.github.io/a2083f20-377e-4dca-a149-a13ae3233901/ rel=canonical><link href=../909ed374-e61f-4332-9619-4dedc93439ba/ rel=prev><link href=../e526860c-b2ec-4be4-862e-06cb5188bd07/ rel=next><link rel=icon href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.14"><title>structural-causal-models - Sean</title><link rel=stylesheet href=../assets/stylesheets/main.342714a4.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Noto+Sans+Korean:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Noto Sans Korean";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../stylesheets/extra.css><link rel=stylesheet href=../stylesheets/links.css><link rel=stylesheet href=https://unpkg.com/katex@0/dist/katex.min.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=blue-grey data-md-color-accent=light-blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#structural-causal-models-scm-in-big-tech-practice class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=Sean class="md-header__button md-logo" aria-label=Sean data-md-component=logo> <img src=../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Sean </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> structural-causal-models </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=blue-grey data-md-color-accent=light-blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=blue-grey data-md-color-accent=light-blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/Joon-Park92/Joon-Park92.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Joon-Park92/Joon-Park92.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=Sean class="md-nav__button md-logo" aria-label=Sean data-md-component=logo> <img src=../img/logo.png alt=logo> </a> Sean </label> <div class=md-nav__source> <a href=https://github.com/Joon-Park92/Joon-Park92.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Joon-Park92/Joon-Park92.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../c0295d5c-ac9d-4a38-a890-a550d8508304/ class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Think </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Think </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../71af9498-4da5-490e-8ca0-41b0d11cc8d7/ class=md-nav__link> <span class=md-ellipsis> problem </span> </a> </li> <li class=md-nav__item> <a href=../2f6da2cc-73a4-4dbb-aa14-4c2280df6a59/ class=md-nav__link> <span class=md-ellipsis> innovation </span> </a> </li> <li class=md-nav__item> <a href=../7ba945a8-e583-4b99-bdd8-5c0f84118c54/ class=md-nav__link> <span class=md-ellipsis> growth </span> </a> </li> <li class=md-nav__item> <a href=../bd21b1dc-6064-48b1-8894-18693847e844/ class=md-nav__link> <span class=md-ellipsis> periodic-phenomenon </span> </a> </li> <li class=md-nav__item> <a href=../e0a0fbf1-1ed1-4b59-ab3f-335ee2fd5ef6/ class=md-nav__link> <span class=md-ellipsis> loneliness </span> </a> </li> <li class=md-nav__item> <a href=../a544e931-db9d-4f20-b003-6a89f2d4a8d0/ class=md-nav__link> <span class=md-ellipsis> pokemon </span> </a> </li> <li class=md-nav__item> <a href=../3bc1acea-5edc-4594-984f-b5f284906524/ class=md-nav__link> <span class=md-ellipsis> duolingo </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Insight </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Insight </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../c5f31887-82ef-40b2-8577-80972dda2033/ class=md-nav__link> <span class=md-ellipsis> 250414 </span> </a> </li> <li class=md-nav__item> <a href=../f4e1ca07-4c91-45ca-8fc6-ecbe07cbf1a1/ class=md-nav__link> <span class=md-ellipsis> ark-invest-24 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Book </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Book </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../cc4e555b-4456-4259-b261-6adb46e70c21/ class=md-nav__link> <span class=md-ellipsis> working-backward </span> </a> </li> <li class=md-nav__item> <a href=../6d61fad8-7e87-41a2-a4a7-95a83d249614/ class=md-nav__link> <span class=md-ellipsis> thinking-in-bets </span> </a> </li> <li class=md-nav__item> <a href=../7a8d3ccf-7ae1-4723-bf7e-36ac47970f2b/ class=md-nav__link> <span class=md-ellipsis> record-of-a-journey-to-mujin </span> </a> </li> <li class=md-nav__item> <a href=../5542ecb9-6658-4096-9cdb-2ac15a54277a/ class=md-nav__link> <span class=md-ellipsis> the-death-of-ivan-ilyitch </span> </a> </li> <li class=md-nav__item> <a href=../6f914835-5ecf-432a-9315-71fcca494238/ class=md-nav__link> <span class=md-ellipsis> the-old-man-and-the-sea </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Papers </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Papers </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../98a670de-3076-4f48-879f-94727bfc8807/ class=md-nav__link> <span class=md-ellipsis> alpha-geometry </span> </a> </li> <li class=md-nav__item> <a href=../19a96d58-26fc-4835-a667-6e21c909a0f1/ class=md-nav__link> <span class=md-ellipsis> two-step-ml-enable-optimized-nano-particle-synthesis </span> </a> </li> <li class=md-nav__item> <a href=../c48e831f-9d8d-4cdd-88f1-9106a9a2db8e/ class=md-nav__link> <span class=md-ellipsis> self-route-rag-lc-hybrid-approach </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Machine Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Machine Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_1> <label class=md-nav__link for=__nav_6_1 id=__nav_6_1_label tabindex=0> <span class=md-ellipsis> ai-agent </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_1_label aria-expanded=false> <label class=md-nav__title for=__nav_6_1> <span class="md-nav__icon md-icon"></span> ai-agent </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../0e8f9f02-0c8d-4764-9952-512a95698684/ class=md-nav__link> <span class=md-ellipsis> pattern </span> </a> </li> <li class=md-nav__item> <a href=../55f9b832-4723-4ac6-aba1-c5222f275773/ class=md-nav__link> <span class=md-ellipsis> improving-hallucination </span> </a> </li> <li class=md-nav__item> <a href=../96a2b494-bb88-4504-869e-2dd3002eb2d7/ class=md-nav__link> <span class=md-ellipsis> deep-research </span> </a> </li> <li class=md-nav__item> <a href=../4a3456c9-5673-41f4-8fe5-03daa8571ffa/ class=md-nav__link> <span class=md-ellipsis> prompt-guide </span> </a> </li> <li class=md-nav__item> <a href=../01a19268-08cb-4b3c-98d6-9c0d48b03a93/ class=md-nav__link> <span class=md-ellipsis> evaluation-of-math-quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_2> <label class=md-nav__link for=__nav_6_2 id=__nav_6_2_label tabindex=0> <span class=md-ellipsis> ml-design-pattern </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2> <span class="md-nav__icon md-icon"></span> ml-design-pattern </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../f8570381-560e-438d-b9f6-5250d6056f36/ class=md-nav__link> <span class=md-ellipsis> transform </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_3> <label class=md-nav__link for=__nav_6_3 id=__nav_6_3_label tabindex=0> <span class=md-ellipsis> theory </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3> <span class="md-nav__icon md-icon"></span> theory </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../e1f6d3f6-8a10-4ea0-a3b8-1167b0c9691f/ class=md-nav__link> <span class=md-ellipsis> singular-value-decomposition </span> </a> </li> <li class=md-nav__item> <a href=../a76b9851-0a4b-498e-b949-012360173f1d/ class=md-nav__link> <span class=md-ellipsis> decision-theory </span> </a> </li> <li class=md-nav__item> <a href=../3b2779be-a240-4dbf-bde2-a67e8519bf03/ class=md-nav__link> <span class=md-ellipsis> markov-decision-process </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4> <label class=md-nav__link for=__nav_6_4 id=__nav_6_4_label tabindex=0> <span class=md-ellipsis> models </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_4_label aria-expanded=false> <label class=md-nav__title for=__nav_6_4> <span class="md-nav__icon md-icon"></span> models </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../3ccafe3b-c24d-4bbc-b8a5-487b3b83cd5a/ class=md-nav__link> <span class=md-ellipsis> gradient-boost </span> </a> </li> <li class=md-nav__item> <a href=../5608e722-eb92-471f-bd22-d563272ce76f/ class=md-nav__link> <span class=md-ellipsis> xgboost </span> </a> </li> <li class=md-nav__item> <a href=../430c4345-4509-464b-afa1-839643cb3e7f/ class=md-nav__link> <span class=md-ellipsis> multi-armed-bandit </span> </a> </li> <li class=md-nav__item> <a href=../4a8e19a2-737f-49e6-bfbc-43c4a15358f3/ class=md-nav__link> <span class=md-ellipsis> ctr-model </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4_5> <label class=md-nav__link for=__nav_6_4_5 id=__nav_6_4_5_label tabindex=0> <span class=md-ellipsis> object-detection </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_4_5_label aria-expanded=false> <label class=md-nav__title for=__nav_6_4_5> <span class="md-nav__icon md-icon"></span> object-detection </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../cd9b93fb-9aeb-4c66-a285-8c2cfb580637/ class=md-nav__link> <span class=md-ellipsis> yolo-outline </span> </a> </li> <li class=md-nav__item> <a href=../180d0c57-3989-4bc7-a33e-36e11e6753a9/ class=md-nav__link> <span class=md-ellipsis> r-cnn-outline </span> </a> </li> <li class=md-nav__item> <a href=../662c2408-9a10-4d9c-9b2e-289909cd2181/ class=md-nav__link> <span class=md-ellipsis> r-cnn </span> </a> </li> <li class=md-nav__item> <a href=../87d3f8f6-0e00-4740-8fd7-5831847fbfb3/ class=md-nav__link> <span class=md-ellipsis> object-detection-metric </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_5> <label class=md-nav__link for=__nav_6_5 id=__nav_6_5_label tabindex=0> <span class=md-ellipsis> metrics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_5_label aria-expanded=false> <label class=md-nav__title for=__nav_6_5> <span class="md-nav__icon md-icon"></span> metrics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../755b070b-41b4-4ad1-896a-e89ed77bdea3/ class=md-nav__link> <span class=md-ellipsis> silhouette-score </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_6> <label class=md-nav__link for=__nav_6_6 id=__nav_6_6_label tabindex=0> <span class=md-ellipsis> operations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6_6> <span class="md-nav__icon md-icon"></span> operations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../420fec6d-e64e-4b4e-9815-2b8f4f1f5d66/ class=md-nav__link> <span class=md-ellipsis> serving-frameworks </span> </a> </li> <li class=md-nav__item> <a href=../97d4abaf-b54b-49e2-9eea-1262f3d60ffa/ class=md-nav__link> <span class=md-ellipsis> key-metrics-form-ml-api </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_7> <label class=md-nav__link for=__nav_6_7 id=__nav_6_7_label tabindex=0> <span class=md-ellipsis> data-pipeline </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_7_label aria-expanded=false> <label class=md-nav__title for=__nav_6_7> <span class="md-nav__icon md-icon"></span> data-pipeline </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../8feb5ca2-1b5d-4e9b-aa95-c3cc19b3fada/ class=md-nav__link> <span class=md-ellipsis> data-pipeline-idempotent </span> </a> </li> <li class=md-nav__item> <a href=../544db2a0-4067-4464-b0d2-dbfcbd67f746/ class=md-nav__link> <span class=md-ellipsis> data-pipeline-best-practice </span> </a> </li> <li class=md-nav__item> <a href=../69c32762-4d5a-46af-980f-65412c50def8/ class=md-nav__link> <span class=md-ellipsis> data-pipeline-design-pattern </span> </a> </li> <li class=md-nav__item> <a href=../44a78a08-56b1-40e8-801f-5220573f7f63/ class=md-nav__link> <span class=md-ellipsis> data-pipeline-etl-elt-pattern </span> </a> </li> <li class=md-nav__item> <a href=../1e3e96b7-2d44-44c5-8987-b1f731d2322a/ class=md-nav__link> <span class=md-ellipsis> data-lake-warehouse-mart </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7 checked> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> Data Analysis </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=true> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Data Analysis </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../33ddecc4-e433-47f3-9dbb-a0b82456d359/ class=md-nav__link> <span class=md-ellipsis> confounder-variable </span> </a> </li> <li class=md-nav__item> <a href=../8ea2fddb-bde7-4e71-bdac-b2f5b31dc35e/ class=md-nav__link> <span class=md-ellipsis> carrying-capacity </span> </a> </li> <li class=md-nav__item> <a href=../430a1ee4-5289-435c-97ea-96d4ab2c6fde/ class=md-nav__link> <span class=md-ellipsis> bayesian-problem-1 </span> </a> </li> <li class=md-nav__item> <a href=../909ed374-e61f-4332-9619-4dedc93439ba/ class=md-nav__link> <span class=md-ellipsis> bayesian-notation </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> structural-causal-models </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> structural-causal-models </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#structural-causal-models-scm-in-big-tech-practice class=md-nav__link> <span class=md-ellipsis> Structural Causal Models (SCM) in Big Tech Practice </span> </a> <nav class=md-nav aria-label="Structural Causal Models (SCM) in Big Tech Practice"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#google-measuring-interventions-with-structural-time-series-models class=md-nav__link> <span class=md-ellipsis> Google: Measuring Interventions with Structural Time-Series Models </span> </a> </li> <li class=md-nav__item> <a href=#meta-facebook-causal-modeling-in-ads-feed-and-marketing-analytics class=md-nav__link> <span class=md-ellipsis> Meta (Facebook): Causal Modeling in Ads, Feed, and Marketing Analytics </span> </a> </li> <li class=md-nav__item> <a href=#amazon-scms-for-recommendations-inventory-and-root-cause-analysis class=md-nav__link> <span class=md-ellipsis> Amazon: SCMs for Recommendations, Inventory, and Root Cause Analysis </span> </a> </li> <li class=md-nav__item> <a href=#other-industry-examples-and-tools class=md-nav__link> <span class=md-ellipsis> Other Industry Examples and Tools </span> </a> </li> <li class=md-nav__item> <a href=#benefits-of-scm-based-causal-inference class=md-nav__link> <span class=md-ellipsis> Benefits of SCM-Based Causal Inference </span> </a> </li> <li class=md-nav__item> <a href=#challenges-and-limitations class=md-nav__link> <span class=md-ellipsis> Challenges and Limitations </span> </a> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex=0> <span class=md-ellipsis> Programming </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Programming </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_1> <label class=md-nav__link for=__nav_8_1 id=__nav_8_1_label tabindex=0> <span class=md-ellipsis> cheat-sheet </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_1_label aria-expanded=false> <label class=md-nav__title for=__nav_8_1> <span class="md-nav__icon md-icon"></span> cheat-sheet </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_1_1> <label class=md-nav__link for=__nav_8_1_1 id=__nav_8_1_1_label tabindex=0> <span class=md-ellipsis> vscode </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_8_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_8_1_1> <span class="md-nav__icon md-icon"></span> vscode </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../e526860c-b2ec-4be4-862e-06cb5188bd07/ class=md-nav__link> <span class=md-ellipsis> devcontainer </span> </a> </li> <li class=md-nav__item> <a href=../8e4310e9-3a6a-4d96-9256-e67659ca51cd/ class=md-nav__link> <span class=md-ellipsis> devcontainer-compose </span> </a> </li> <li class=md-nav__item> <a href=../46e14fc0-2be9-4b9f-a17a-e72ea38e6fe3/ class=md-nav__link> <span class=md-ellipsis> debug </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../0aed534e-ea29-417f-a8df-c3e52e03360d/ class=md-nav__link> <span class=md-ellipsis> golang </span> </a> </li> <li class=md-nav__item> <a href=../77b75667-9746-45c3-80a2-d8c45a40882a/ class=md-nav__link> <span class=md-ellipsis> pdb </span> </a> </li> <li class=md-nav__item> <a href=../953c51f3-f6f5-42d8-a87a-fb7f9493436d/ class=md-nav__link> <span class=md-ellipsis> dlv </span> </a> </li> <li class=md-nav__item> <a href=../3e95cbc6-7ecd-4b56-9ace-fa9df6f6d9b0/ class=md-nav__link> <span class=md-ellipsis> awk </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_2> <label class=md-nav__link for=__nav_8_2 id=__nav_8_2_label tabindex=0> <span class=md-ellipsis> architecture-pattern </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_2_label aria-expanded=false> <label class=md-nav__title for=__nav_8_2> <span class="md-nav__icon md-icon"></span> architecture-pattern </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../c4ae6334-c1c2-4452-890c-8a022d6c1246/ class=md-nav__link> <span class=md-ellipsis> uow-pattern </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_3> <label class=md-nav__link for=__nav_8_3 id=__nav_8_3_label tabindex=0> <span class=md-ellipsis> design-pattern </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_3_label aria-expanded=false> <label class=md-nav__title for=__nav_8_3> <span class="md-nav__icon md-icon"></span> design-pattern </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../abe10a12-9498-4435-816e-a967daeadd3f/ class=md-nav__link> <span class=md-ellipsis> diagram </span> </a> </li> <li class=md-nav__item> <a href=../5a69e196-3aa4-4c2c-858f-3b19507f6a9d/ class=md-nav__link> <span class=md-ellipsis> abstract-factory-pattern </span> </a> </li> <li class=md-nav__item> <a href=../5c2407d0-1b72-4886-9c6c-f73897c77475/ class=md-nav__link> <span class=md-ellipsis> builder-pattern </span> </a> </li> <li class=md-nav__item> <a href=../47efac8a-0a2b-4ca1-8154-022be7d39b79/ class=md-nav__link> <span class=md-ellipsis> singleton-pattern </span> </a> </li> <li class=md-nav__item> <a href=../883d7b99-7492-4055-9c0d-f742b6c6b94c/ class=md-nav__link> <span class=md-ellipsis> proxy-pattern </span> </a> </li> <li class=md-nav__item> <a href=../2b665dac-9091-4267-83de-36e9c3e15b6c/ class=md-nav__link> <span class=md-ellipsis> decorator-pattern </span> </a> </li> <li class=md-nav__item> <a href=../41d4ab75-8c96-4948-9616-db36d04b6b96/ class=md-nav__link> <span class=md-ellipsis> observer-pattern </span> </a> </li> <li class=md-nav__item> <a href=../743dc6d3-3c82-4714-852d-bb65861bbeb2/ class=md-nav__link> <span class=md-ellipsis> strategy-pattern </span> </a> </li> <li class=md-nav__item> <a href=../a74d9002-c7e9-4d06-b710-de589255cc97/ class=md-nav__link> <span class=md-ellipsis> memento-pattern </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_4> <label class=md-nav__link for=__nav_8_4 id=__nav_8_4_label tabindex=0> <span class=md-ellipsis> api-design </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_4_label aria-expanded=false> <label class=md-nav__title for=__nav_8_4> <span class="md-nav__icon md-icon"></span> api-design </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../70aaa37e-6bf4-4cda-9dab-756b32c2e6a8/ class=md-nav__link> <span class=md-ellipsis> resource-oriented-design </span> </a> </li> <li class=md-nav__item> <a href=../8ef7098d-dcc8-4211-9df2-adf369932457/ class=md-nav__link> <span class=md-ellipsis> aip-124 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_5> <label class=md-nav__link for=__nav_8_5 id=__nav_8_5_label tabindex=0> <span class=md-ellipsis> uml </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_5_label aria-expanded=false> <label class=md-nav__title for=__nav_8_5> <span class="md-nav__icon md-icon"></span> uml </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../1d7be764-7667-499d-8845-725d25979152/ class=md-nav__link> <span class=md-ellipsis> sequence-chart </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_6> <label class=md-nav__link for=__nav_8_6 id=__nav_8_6_label tabindex=0> <span class=md-ellipsis> test </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_6_label aria-expanded=false> <label class=md-nav__title for=__nav_8_6> <span class="md-nav__icon md-icon"></span> test </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ebc61d65-2267-48ec-b957-1915d16c3891/ class=md-nav__link> <span class=md-ellipsis> test-must-be-actionable </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_7> <label class=md-nav__link for=__nav_8_7 id=__nav_8_7_label tabindex=0> <span class=md-ellipsis> web </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_7_label aria-expanded=false> <label class=md-nav__title for=__nav_8_7> <span class="md-nav__icon md-icon"></span> web </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dc73f07f-be90-45d6-a461-ba5bdcd5e163/ class=md-nav__link> <span class=md-ellipsis> auth-basic </span> </a> </li> <li class=md-nav__item> <a href=../d3c922e8-8eee-4d47-bfdb-54709ee13cf8/ class=md-nav__link> <span class=md-ellipsis> social-login </span> </a> </li> <li class=md-nav__item> <a href=../8477ba61-0609-4ac2-b988-7cbf8854c739/ class=md-nav__link> <span class=md-ellipsis> ca-certification </span> </a> </li> <li class=md-nav__item> <a href=../4ebc9c2a-c6c4-4427-8ff8-056a8ccbc38b/ class=md-nav__link> <span class=md-ellipsis> tcp-udp </span> </a> </li> <li class=md-nav__item> <a href=../3742ec8b-5f6a-46fc-b3c9-08ad198df8dc/ class=md-nav__link> <span class=md-ellipsis> osi-model </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_8> <label class=md-nav__link for=__nav_8_8 id=__nav_8_8_label tabindex=0> <span class=md-ellipsis> infra </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8_8> <span class="md-nav__icon md-icon"></span> infra </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../0d9644cb-9846-49ac-b697-3aac254c6543/ class=md-nav__link> <span class=md-ellipsis> slo-sli-sla </span> </a> </li> <li class=md-nav__item> <a href=../f01005fd-8d79-4a9a-bb6f-f8945e77f5d5/ class=md-nav__link> <span class=md-ellipsis> dora-metrics </span> </a> </li> <li class=md-nav__item> <a href=../1a49014b-e4ad-4124-89fc-1ea4e96e8c35/ class=md-nav__link> <span class=md-ellipsis> operational-excelence </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_8_4> <label class=md-nav__link for=__nav_8_8_4 id=__nav_8_8_4_label tabindex=0> <span class=md-ellipsis> database </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_8_8_4_label aria-expanded=false> <label class=md-nav__title for=__nav_8_8_4> <span class="md-nav__icon md-icon"></span> database </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../67718e56-966a-4592-8c6c-b5828d86dc56/ class=md-nav__link> <span class=md-ellipsis> transaction-and-lock </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_8_5> <label class=md-nav__link for=__nav_8_8_5 id=__nav_8_8_5_label tabindex=0> <span class=md-ellipsis> monitoring </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_8_8_5_label aria-expanded=false> <label class=md-nav__title for=__nav_8_8_5> <span class="md-nav__icon md-icon"></span> monitoring </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ca6f533e-9a0c-492c-9063-70bac671ae75/ class=md-nav__link> <span class=md-ellipsis> basic-loki-query </span> </a> </li> <li class=md-nav__item> <a href=../69a053ab-db6a-480f-8557-c127a2a6da79/ class=md-nav__link> <span class=md-ellipsis> basic-promql </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_8_6> <label class=md-nav__link for=__nav_8_8_6 id=__nav_8_8_6_label tabindex=0> <span class=md-ellipsis> k8s </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_8_8_6_label aria-expanded=false> <label class=md-nav__title for=__nav_8_8_6> <span class="md-nav__icon md-icon"></span> k8s </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../00ec5c52-4cac-4577-a1e5-98d4fbde43dd/ class=md-nav__link> <span class=md-ellipsis> resource </span> </a> </li> <li class=md-nav__item> <a href=../444f81ea-f01b-47a3-9748-21727479ee90/ class=md-nav__link> <span class=md-ellipsis> deployment </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_8_7> <label class=md-nav__link for=__nav_8_8_7 id=__nav_8_8_7_label tabindex=0> <span class=md-ellipsis> ansible </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_8_8_7_label aria-expanded=false> <label class=md-nav__title for=__nav_8_8_7> <span class="md-nav__icon md-icon"></span> ansible </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../881276a7-c2cf-49ec-8e9e-e0e4fb328e65/ class=md-nav__link> <span class=md-ellipsis> best-practice </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_8_8> <label class=md-nav__link for=__nav_8_8_8 id=__nav_8_8_8_label tabindex=0> <span class=md-ellipsis> gitops </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_8_8_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8_8_8> <span class="md-nav__icon md-icon"></span> gitops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../11fab0ac-da1f-4699-9f87-23ddf3a1242b/ class=md-nav__link> <span class=md-ellipsis> argo-cd </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_8_9> <label class=md-nav__link for=__nav_8_8_9 id=__nav_8_8_9_label tabindex=0> <span class=md-ellipsis> terraform </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_8_8_9_label aria-expanded=false> <label class=md-nav__title for=__nav_8_8_9> <span class="md-nav__icon md-icon"></span> terraform </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../7d81fa63-d3fa-46c9-954d-f700780cdcf5/ class=md-nav__link> <span class=md-ellipsis> basic </span> </a> </li> <li class=md-nav__item> <a href=../9f796320-bd12-4bd9-ad27-420fecb00aa0/ class=md-nav__link> <span class=md-ellipsis> module </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_9> <label class=md-nav__link for=__nav_9 id=__nav_9_label tabindex=0> <span class=md-ellipsis> Mathematics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_9_label aria-expanded=false> <label class=md-nav__title for=__nav_9> <span class="md-nav__icon md-icon"></span> Mathematics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../fe3a1ef1-ac09-47dd-8188-870c2b69e147/ class=md-nav__link> <span class=md-ellipsis> modern-mathematics </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_9_2> <label class=md-nav__link for=__nav_9_2 id=__nav_9_2_label tabindex=0> <span class=md-ellipsis> linear-algebra </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_9_2_label aria-expanded=false> <label class=md-nav__title for=__nav_9_2> <span class="md-nav__icon md-icon"></span> linear-algebra </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../356067df-ccd5-4f2f-a732-f3e30fb096c4/ class=md-nav__link> <span class=md-ellipsis> laplace-fourier-transform </span> </a> </li> <li class=md-nav__item> <a href=../2ecc0325-cbba-4315-a434-a742533f59fd/ class=md-nav__link> <span class=md-ellipsis> jordan-normal-form </span> </a> </li> <li class=md-nav__item> <a href=../fc99afe0-532e-4a85-ba15-fdd5f7cd671f/ class=md-nav__link> <span class=md-ellipsis> spectral-theory </span> </a> </li> <li class=md-nav__item> <a href=../e1f6d3f6-8a10-4ea0-a3b8-1167b0c9691f/ class=md-nav__link> <span class=md-ellipsis> singular-value-decomposition </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_9_3> <label class=md-nav__link for=__nav_9_3 id=__nav_9_3_label tabindex=0> <span class=md-ellipsis> abstract-algebra </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_9_3_label aria-expanded=false> <label class=md-nav__title for=__nav_9_3> <span class="md-nav__icon md-icon"></span> abstract-algebra </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../94229181-dc2c-4e33-ad8d-3e449257edbe/ class=md-nav__link> <span class=md-ellipsis> ideal </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_9_4> <label class=md-nav__link for=__nav_9_4 id=__nav_9_4_label tabindex=0> <span class=md-ellipsis> analysis </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_9_4_label aria-expanded=false> <label class=md-nav__title for=__nav_9_4> <span class="md-nav__icon md-icon"></span> analysis </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../5457aa52-7690-4906-afc2-8243ab67a390/ class=md-nav__link> <span class=md-ellipsis> basic </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_9_5> <label class=md-nav__link for=__nav_9_5 id=__nav_9_5_label tabindex=0> <span class=md-ellipsis> logic </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_9_5_label aria-expanded=false> <label class=md-nav__title for=__nav_9_5> <span class="md-nav__icon md-icon"></span> logic </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ecb6dfa9-eb48-4183-8e04-0b2d87f2fcea/ class=md-nav__link> <span class=md-ellipsis> completeness-soundness-consistency </span> </a> </li> <li class=md-nav__item> <a href=../1d76b428-9e2d-47ff-a222-33e64b28e53c/ class=md-nav__link> <span class=md-ellipsis> formal-system </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_9_6> <label class=md-nav__link for=__nav_9_6 id=__nav_9_6_label tabindex=0> <span class=md-ellipsis> etc </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_9_6_label aria-expanded=false> <label class=md-nav__title for=__nav_9_6> <span class="md-nav__icon md-icon"></span> etc </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../b199b805-3a46-4d2e-9293-c78266395c1f/ class=md-nav__link> <span class=md-ellipsis> distance-vs-metric-vs-norm </span> </a> </li> <li class=md-nav__item> <a href=../5601ba05-e7ff-4dd2-a5fc-0be44f641911/ class=md-nav__link> <span class=md-ellipsis> tensor </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_10> <label class=md-nav__link for=__nav_10 id=__nav_10_label tabindex=0> <span class=md-ellipsis> Economics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_10_label aria-expanded=false> <label class=md-nav__title for=__nav_10> <span class="md-nav__icon md-icon"></span> Economics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../998de948-f260-4548-ac8e-d776cb700c5b/ class=md-nav__link> <span class=md-ellipsis> causal-relationship </span> </a> </li> <li class=md-nav__item> <a href=../7b126bd8-5469-4c24-bee7-782308dbf083/ class=md-nav__link> <span class=md-ellipsis> economic-agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_11> <label class=md-nav__link for=__nav_11 id=__nav_11_label tabindex=0> <span class=md-ellipsis> Philosophy </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_11_label aria-expanded=false> <label class=md-nav__title for=__nav_11> <span class="md-nav__icon md-icon"></span> Philosophy </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../62bdf711-6616-41fe-a861-9b3b99a2e988/ class=md-nav__link> <span class=md-ellipsis> history </span> </a> </li> <li class=md-nav__item> <a href=../b173354e-9935-4dfe-ab04-77e62427478a/ class=md-nav__link> <span class=md-ellipsis> kant </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../newsletter/0_newsletter_index/ class=md-nav__link> <span class=md-ellipsis> Newsletters </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#structural-causal-models-scm-in-big-tech-practice class=md-nav__link> <span class=md-ellipsis> Structural Causal Models (SCM) in Big Tech Practice </span> </a> <nav class=md-nav aria-label="Structural Causal Models (SCM) in Big Tech Practice"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#google-measuring-interventions-with-structural-time-series-models class=md-nav__link> <span class=md-ellipsis> Google: Measuring Interventions with Structural Time-Series Models </span> </a> </li> <li class=md-nav__item> <a href=#meta-facebook-causal-modeling-in-ads-feed-and-marketing-analytics class=md-nav__link> <span class=md-ellipsis> Meta (Facebook): Causal Modeling in Ads, Feed, and Marketing Analytics </span> </a> </li> <li class=md-nav__item> <a href=#amazon-scms-for-recommendations-inventory-and-root-cause-analysis class=md-nav__link> <span class=md-ellipsis> Amazon: SCMs for Recommendations, Inventory, and Root Cause Analysis </span> </a> </li> <li class=md-nav__item> <a href=#other-industry-examples-and-tools class=md-nav__link> <span class=md-ellipsis> Other Industry Examples and Tools </span> </a> </li> <li class=md-nav__item> <a href=#benefits-of-scm-based-causal-inference class=md-nav__link> <span class=md-ellipsis> Benefits of SCM-Based Causal Inference </span> </a> </li> <li class=md-nav__item> <a href=#challenges-and-limitations class=md-nav__link> <span class=md-ellipsis> Challenges and Limitations </span> </a> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>structural-causal-models</h1> <h2 id=structural-causal-models-scm-in-big-tech-practice>Structural Causal Models (SCM) in Big Tech Practice<a class=headerlink href=#structural-causal-models-scm-in-big-tech-practice title="Permanent link">âš‘</a></h2> <p>Structural Causal Models (SCMs) are a framework for explicitly modeling cause-and-effect using directed acyclic graphs (DAGs) and structural equations. Big tech companies like Google, Meta (Facebook), Amazon, and others have embraced SCM-based causal inference to tackle practical problems that go beyond correlation. By using SCMs, they can <strong>understand the impact of interventions, diagnose business metrics, and optimize decisions</strong> in ways that traditional predictive ML cannot (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=People%20at%20Facebook%20seem%20to,%E2%80%9Cdifference%20between%20seeing%20and%20doing%E2%80%9D">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>) (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=But%20the%20seeing%20part%20is,we%20might%20not%20see%20an">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>). Below, we explore how these companies apply SCMs in practice, including real use cases, the problems solved, how DAGs/structural equations are used, benefits and limitations, and tools or code examples.</p> <h3 id=google-measuring-interventions-with-structural-time-series-models>Google: Measuring Interventions with Structural Time-Series Models<a class=headerlink href=#google-measuring-interventions-with-structural-time-series-models title="Permanent link">âš‘</a></h3> <p>Google has applied SCM principles to measure the causal impact of interventions (like advertising campaigns or product changes) on key metrics over time. A prime example is Googleâ€™s <strong>CausalImpact</strong> framework, which uses a Bayesian structural <strong>state-space time-series model</strong> to estimate what would have happened <em>without</em> the intervention (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=An%20important%20problem%20in%20econometrics,differences">Inferring causal impact using Bayesian structural time-series models</a>). This approach constructs a <strong>counterfactual</strong> (synthetic control) from past data and covariates, then compares it to actual outcomes to attribute lift caused by the intervention. In one application, Google researchers evaluated the effect of an online ad campaign on search site visits using this method (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=schemes%2C%20state,The%20CausalImpact">Inferring causal impact using Bayesian structural time-series models</a>).</p> <p><strong>Problem:</strong> How to quantify the incremental effect of a marketing or product intervention when no A/B test was run (e.g. measuring ad campaign ROI or a feature launch impact).</p> <p><strong>Approach:</strong> Googleâ€™s model predicts the counterfactual market response had the intervention not occurred, by leveraging a diffusion-regression state-space model (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=An%20important%20problem%20in%20econometrics,differences">Inferring causal impact using Bayesian structural time-series models</a>). Essentially, it fits a structural time-series on pre-intervention data (using control time series as covariates) and projects it forward through the intervention period. Any deviation of actual metrics from this projection is attributed to the interventionâ€™s causal impact. The modelâ€™s DAG is implicit in the time-series structure: it assumes past values and contemporaneous controls cause current outcomes.</p> <p><strong>SCM Details:</strong> While not a DAG on a whiteboard, the structural time-series has <em>structural equations</em> defining how todayâ€™s outcome depends on yesterdayâ€™s state and control variables. This captures causal assumptions (e.g. that the intervention affects the outcome but not vice versa, and covariates affect outcome). The approach improves on simpler methods like difference-in-differences by (i) inferring <strong>temporal patterns</strong> of impact (how effect evolves over time), (ii) incorporating prior knowledge in a Bayesian way, and (iii) allowing multiple covariates (like a traditional SCM with many parent variables) (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=schemes%2C%20state,The%20CausalImpact">Inferring causal impact using Bayesian structural time-series models</a>). These covariates act as a <em>synthetic control</em>, helping to adjust for external influences and better isolate the interventionâ€™s effect.</p> <p><strong>Benefits:</strong> Googleâ€™s use of SCM here provides a <strong>quantitative estimate of causal effect</strong> without an experiment. It outputs not just an overall lift but a time series of the effect, which is crucial for understanding dynamics (e.g. did the effect wear off or grow?) (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=schemes%2C%20state,The%20CausalImpact">Inferring causal impact using Bayesian structural time-series models</a>). It also naturally provides credibility intervals via Bayesian inference, conveying uncertainty. Google found this invaluable for marketing analytics: advertisers can see how much a campaign <strong>truly drove metrics</strong> (like conversions or searches) to optimize budget allocation (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=An%20important%20problem%20in%20econometrics,infer%20the%20temporal%20evolution">Inferring causal impact using Bayesian structural time-series models</a>). Google released the <strong>CausalImpact</strong> R package implementing this, which has been widely adopted in industry (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=data,an%20implementation%20of%20our%20approach">Inferring causal impact using Bayesian structural time-series models</a>).</p> <p><strong>Example (Code):</strong> Using the CausalImpact library is straightforward. Analysts specify the time periods and data, and the library fits the structural model and computes effects. For instance, in R one can do:</p> <div class=highlight><pre><span></span><code><span class=c1># `data` has outcome and controls, pre.period/post.period define intervention timing</span>
<span class=n>impact</span><span class=w> </span><span class=o>&lt;-</span><span class=w> </span><span class=nf>CausalImpact</span><span class=p>(</span><span class=n>data</span><span class=p>,</span><span class=w> </span><span class=n>pre.period</span><span class=p>,</span><span class=w> </span><span class=n>post.period</span><span class=p>)</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>impact</span><span class=p>)</span>
</code></pre></div> <p>This will assemble the structural time-series model, perform posterior inference, and then plot the actual vs. predicted counterfactual outcomes (<a href="https://cran.r-project.org/web/packages/CausalImpact/vignettes/CausalImpact.html#:~:text=impact%20%3C">CausalImpact</a>). The resulting plot typically shows three panels: the observed vs. counterfactual trend, the pointwise causal effect each day, and the cumulative effect (<a href="https://cran.r-project.org/web/packages/CausalImpact/vignettes/CausalImpact.html#:~:text=By%20default%2C%20the%20plot%20contains,The%20third%20panel%20adds%20up">CausalImpact</a>). Such tools exemplify how Google brought SCM to practitionersâ€™ fingertips.</p> <p><strong>Limitations:</strong> SCM results are only as valid as the model assumptions. Googleâ€™s researchers noted the â€œstrengths and limitationsâ€ of their state-space SCM for causal attribution (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=i,an%20implementation%20of%20our%20approach">Inferring causal impact using Bayesian structural time-series models</a>). One limitation is that if important driving factors are omitted (unobserved confounders), the causal estimate may be biased. Also, structural time-series models assume the relationship between covariates and outcome remains stable â€“ if the intervention fundamentally changes the system dynamics, the counterfactual may be mis-specified. Nevertheless, when randomized experiments are infeasible, Googleâ€™s case shows that SCMs provide a practical alternative, with the <strong>caveat</strong> that analysts must carefully validate the model (e.g. through placebo tests or sensitivity analysis).</p> <h3 id=meta-facebook-causal-modeling-in-ads-feed-and-marketing-analytics>Meta (Facebook): Causal Modeling in Ads, Feed, and Marketing Analytics<a class=headerlink href=#meta-facebook-causal-modeling-in-ads-feed-and-marketing-analytics title="Permanent link">âš‘</a></h3> <p>Facebook (Meta) deals with massive social systems and advertising platforms where causal inference is critical. They formed an Experimental Design &amp; Causal Inference team to improve decision-making across the company (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=,observational%20data%2C%20and%20to%20generalizability">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>). This team tackles problems ranging from <strong>adaptive experiments</strong> (e.g. contextual bandits for News Feed) to <strong>heterogeneous treatment effect</strong> modeling with ML and <strong>observational causal inference</strong> at scale (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=,observational%20data%2C%20and%20to%20generalizability">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>). Several practical applications at Meta illustrate SCM usage:</p> <ul> <li> <p><strong>Marketing Mix Modeling (MMM) with Robyn:</strong> Metaâ€™s open-source tool <strong>Robyn</strong> is an advanced MMM library that embodies causal principles. MMM aims to attribute outcomes (e.g. sales) to different marketing channels (TV, search ads, social media, etc.). Traditional MMM is essentially a regression, but Robyn introduces rigor through regularization and ground-truth calibration. Developed by Metaâ€™s Marketing Science team, Robyn uses techniques like ridge regression to handle multicollinearity and Facebookâ€™s Prophet to account for seasonal effects (<a href="https://facebookexperimental.github.io/Robyn/#:~:text=,trend%2C%20seasonality%20and%20holidays%20patterns">Robyn</a>) (<a href="https://facebookexperimental.github.io/Robyn/#:~:text=,trend%2C%20seasonality%20and%20holidays%20patterns">Robyn</a>). While not explicitly a DAG, itâ€™s an <strong>â€œAI/ML-poweredâ€ structural model</strong> where each channelâ€™s spend is a cause of sales. Robyn can even integrate experimental results (Facebook lift tests, geo experiments) to <strong>calibrate</strong> the attribution so it aligns with causal reality (<a href="https://facebookexperimental.github.io/Robyn/#:~:text=,truth">Robyn</a>).</p> <p><strong>Problem:</strong> Companies need to know the true contribution of each advertising channel on conversions to optimize budget. Direct experiments on all channels simultaneously are impossible, so an observational causal model is needed. <strong>How SCM/DAG is used:</strong> Analysts using Robyn implicitly assume a causal graph where each marketing channel influences the outcome, possibly with some interactions. They may include control factors (economic trends, etc.) as confounders in the model. Although Robynâ€™s default is a black-box optimization, Meta emphasizes incorporating domain knowledge. In fact, a Meta marketing scientist extended Robyn by adding an explicit <strong>Structural Equation Model (SEM)</strong> layer (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=To%20care%20about%20the%20above,to%20incorporate%20Structural%20Equasion%20Modeling">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>). By doing so, they modeled the causal structure among media channels (e.g. a brand awareness channel affects later retargeting response) to improve attribution fairness. This is effectively adding a DAG on top of Robynâ€™s regression, acknowledging that channels have a causal hierarchy (upper-funnel vs lower-funnel effects) (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=However%2C%20it%20should%20be%20taken,Customers">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>) (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=Moreover%2C%20it%20can%20be%20the,and%20the%20model%20error%20term">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>).</p> <p><strong>Benefits:</strong> SCM thinking in MMM helps avoid mis-attributing credit. For example, without causal structure, an upper-funnel channel like TV might look ineffective because its effect is indirect (through driving people to search later). By considering a causal graph, Metaâ€™s analysts ensure each channelâ€™s role is properly valued (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=practical%20case%2C%20each%20ad%20has,endogeneity%20from%20a%20theoretical%20point">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>) (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=Moreover%2C%20it%20can%20be%20the,and%20the%20model%20error%20term">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>). The <strong>open-source Robyn</strong> tool democratizes this, letting practitioners run complex causal attributions easily (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=Currently%2C%20some%20big%20tech%20companies,so%20on%20besides%20the%20above">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>). Robyn shows how big tech provides practical tools that bake in SCM ideas (like accounting for <strong>carryover effects</strong> and diminishing returns, which are essentially structural assumptions about time-lagged causation).</p> <p><strong>Limitations:</strong> Even with MMM, there are limitations â€“ multicollinearity and confounding can make it hard to distinguish effects. Robyn mitigates some by regularization and by encouraging experiments for validation (<a href="https://facebookexperimental.github.io/Robyn/#:~:text=,truth">Robyn</a>). But a limitation is that MMM is still an observational approach; if some channelsâ€™ spend is correlated with unobserved factors (e.g. competitor actions), the model may attribute effects incorrectly. Metaâ€™s inclusion of experimental calibration addresses this partially, showing that <strong>SCMs often work best in conjunction with some experimental data</strong> to anchor them in reality (<a href="https://facebookexperimental.github.io/Robyn/#:~:text=,truth">Robyn</a>).</p> </li> <li> <p><strong>Social Network Spillover Effects:</strong> In Facebookâ€™s social products, <strong>network effects</strong> violate the usual assumption of independent units. For instance, if Facebook shows a new feature to some users, their friends might also be indirectly affected (spillover), making A/B test analysis tricky. Facebook researchers turned to SCMs in the form of <strong>network causal graphs</strong> to handle this. They developed the concept of <strong>causal network motifs</strong>, which characterizes a userâ€™s exposure by the treatment status of their neighbors (<a href="https://dl.acm.org/doi/fullHtml/10.1145/3442381.3449845#:~:text=Causal%20Network%20Motifs%3A%20Identifying%20Heterogeneous,networks%3B%20and%20then%20we">Causal Network Motifs: Identifying Heterogeneous Spillover Effects ...</a>). In a 2021 study, they used these motifs to identify heterogeneous spillover effects in A/B tests (<a href="https://dl.acm.org/doi/fullHtml/10.1145/3442381.3449845#:~:text=Causal%20Network%20Motifs%3A%20Identifying%20Heterogeneous,networks%3B%20and%20then%20we">Causal Network Motifs: Identifying Heterogeneous Spillover Effects ...</a>) (<a href="https://wine2021-exp.github.io/#:~:text=,Conference%202021%2C%20pages%203359%E2%80%933370%2C%202021">Spillover Effects in Online field experiments: Opportunities and challenges | WINEâ€™2021 Experiment Design</a>). Essentially, they enumerated small network patterns (ego networks) as pseudo-variables in a causal model â€“ e.g. â€œuser was treated, X friends treatedâ€ as a condition â€“ then used a tree-based algorithm to estimate effects under each condition. This approach is an application of DAGs on a <strong>network: nodes are users, edges are friendships, and causal arrows flow from a userâ€™s treatment to both their outcome and their friendsâ€™ outcomes</strong>.</p> <p><strong>Problem:</strong> Standard A/B test analysis assumes one userâ€™s treatment doesnâ€™t affect another (SUTVA). On Facebook or Instagram, this is false due to social interactions (for example, one userâ€™s adoption of a feature could influence friendsâ€™ engagement).</p> <p><strong>Approach:</strong> Model the social graph as part of the causal structure. Facebookâ€™s causal motifs effectively partition the graph into clusters or exposure categories, acknowledging the DAG of influence between friends. By doing so, they can estimate <strong>direct effects</strong> (on treated users) and <strong>indirect effects</strong> (on their untreated friends) separately (<a href="https://wine2021-exp.github.io/#:~:text=,8">Spillover Effects in Online field experiments: Opportunities and challenges | WINEâ€™2021 Experiment Design</a>) (<a href="https://wine2021-exp.github.io/#:~:text=,In%20social%20network%20experiments">Spillover Effects in Online field experiments: Opportunities and challenges | WINEâ€™2021 Experiment Design</a>). The structural causal model here might have a form: a userâ€™s outcome = f(their treatment, number of treated neighbors). This is an explicit causal equation incorporating network structure.</p> <p><strong>Benefits:</strong> This SCM approach allowed Facebook to measure and correct for interference, leading to more reliable conclusions from experiments. It helps answer questions like â€œDid the featureâ€™s apparent effect come partly via network contagion?â€ and <strong>quantify peer effects</strong>. Such insights are crucial when rolling out features â€“ they inform whether network effects will amplify or dilute the impact. By identifying these patterns, Facebook can design better experiments (e.g. cluster randomized trials) and ultimately features that leverage positive network effects.</p> <p><strong>Limitations:</strong> Modeling full social networks is extremely complex. Facebookâ€™s method had to simplify (e.g. only consider 1-hop neighbors, or bucket the number of treated friends) (<a href="https://wine2021-exp.github.io/#:~:text=,18%2C%2033">Spillover Effects in Online field experiments: Opportunities and challenges | WINEâ€™2021 Experiment Design</a>) (<a href="https://wine2021-exp.github.io/#:~:text=where%20the%20input%20is%20the,and%20then%20define%20exposure%20conditions">Spillover Effects in Online field experiments: Opportunities and challenges | WINEâ€™2021 Experiment Design</a>). These assumptions could be wrong or too simplistic in some cases (not all friendships are equal, effects might accumulate nonlinearly). Thereâ€™s also a <strong>combinatorial explosion</strong> of possible network structures â€“ their motif approach is a clever reduction, but it may not capture all nuances. In practice, implementing SCMs for networks requires heavy computation and careful validation. Still, itâ€™s a necessary step when pure A/B testing falls short due to interference.</p> </li> <li> <p><strong>Ads Measurement and Causal Validation:</strong> Facebookâ€™s core business is online advertising, and they extensively use causal inference to measure ad effectiveness. They run thousands of randomized <strong>lift studies</strong> but also investigate observational methods for scenarios where experiments arenâ€™t available. A noteworthy finding at Facebook was that <strong>even with very rich data, purely observational causal models can be significantly wrong</strong> when estimating ad ROI. In a comparison of 15 large ad campaigns, Facebookâ€™s researchers applied state-of-the-art observational models (essentially SCMs with many covariates) and compared them to ground-truth experimental results. The observational methods often <strong>overestimated the adâ€™s effect (or sometimes underestimated), with errors up to a factor of 3</strong> (<a href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf#:~:text=Generally%2C%20the%20observational%20methods%20overestimate,our%20paper%2C%20namely%2C%20to%20shed"></a>). In other words, despite using an SCM approach to control for user features and behaviors, hidden biases remained (<a href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf#:~:text=An%20analysis%20of%20our%2015,a%20factor%20of%20three%20across"></a>). This demonstrated a key limitation: if <strong>any confounder is unobserved or the model form is wrong, an SCM can give false answers</strong>. The lesson for Facebook was that investment in experimentation and causal data collection is crucial (<a href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf#:~:text=as%20is%20thought%20in%20the,including%20advertising%2C%20pricing%2C%20promotions%2C%20and"></a>) (<a href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf#:~:text=effects%20we%20observe%20in%20digital,data%20prove%20inadequate%20to%20yield"></a>). They use SCMs to augment experiments (e.g. stratified analysis, heterogeneity modeling) and to analyze observational data only as a last resort, always aware of the uncertainty.</p> <p><strong>Conclusion for Meta:</strong> Facebookâ€™s experience shows SCMs are powerful â€“ enabling things like MMM attribution, policy simulations, network effect measurement â€“ but they also <strong>recognize the pitfalls</strong>. Theyâ€™ve built internal tooling (mostly in R or Python) to make causal analysis easier for engineers. For example, Facebookâ€™s analysts often use Python libraries like <strong>DoWhy or EconML</strong> (Facebook is part of the PyWhy community, see below) or custom R scripts for causal inference. However, they stress that these methods complement, not replace, a rigorous experimentation culture (<a href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf#:~:text=effects%20we%20observe%20in%20digital,data%20prove%20inadequate%20to%20yield"></a>). The <strong>advantage of SCMs</strong> at Facebook is in scenarios where experiments canâ€™t be done (for ethical, logistical, or interference reasons) â€“ there, SCMs provide a best-effort answer with explicit assumptions, which can then be debated and improved.</p> </li> </ul> <h3 id=amazon-scms-for-recommendations-inventory-and-root-cause-analysis>Amazon: SCMs for Recommendations, Inventory, and Root Cause Analysis<a class=headerlink href=#amazon-scms-for-recommendations-inventory-and-root-cause-analysis title="Permanent link">âš‘</a></h3> <p>Amazon applies structural causal models across both their retail business and cloud (AWS) services, to drive decision-making for e-commerce and to offer solutions to clients. Two concrete contexts are:</p> <ul> <li> <p><strong>Causal Evaluation of Seller Recommendations:</strong> Amazonâ€™s marketplace has programs like <strong>Fulfillment by Amazon (FBA)</strong> that third-party sellers can opt into. Amazon provides recommendations to sellers (e.g. â€œstock more of product X next monthâ€ or â€œuse this advertising optionâ€) and wants to know if following these recommendations <strong>causally improves seller outcomes</strong>. The challenge is <strong>selection bias</strong>: sellers who follow recommendations might be systematically different (more savvy, larger inventory, etc.) than those who ignore them (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=seller%20populations%2C%20those%20who%20follow,not%20follow%20the%20same%20recommendation">Removing selection bias from evaluation of recommendations - Amazon Science</a>). Thus, naively comparing their sales could mislead (this is a classic confounding problem). To solve this, Amazonâ€™s scientists built an <strong>SCM using double machine learning (DML)</strong> (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=At%20this%20year%E2%80%99s%20meeting%20of,the%20effects%20of%20FBA%20recommendations">Removing selection bias from evaluation of recommendations - Amazon Science</a>). This approach, based on econometric theory, essentially uses two ML models: one predicts the â€œtreatmentâ€ (sellerâ€™s likelihood to follow the recommendation) and another predicts the outcome (sales or revenue), and then combines them to isolate the causal effect of the recommendation (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=To%20build%20the%20causal%20model%2C,selection%20bias%20that%20can%E2%80%99t%20already">Removing selection bias from evaluation of recommendations - Amazon Science</a>). This is aligned with the <strong>structural equation model</strong>: one equation for treatment assignment, one for outcome, with an explicit correction for selection.</p> <p><strong>Problem:</strong> Does using FBA recommendations actually increase a sellerâ€™s performance metrics, and by how much? (Important for proving the value of Amazonâ€™s advice and for improving the recommendation system.)</p> <p><strong>SCM Approach:</strong> Amazonâ€™s team specified a causal model where: - <em>Z</em> = sellerâ€™s attributes and past behavior (covariates) - <em>T</em> = whether seller followed the recommendation (treatment) - <em>Y</em> = outcome like revenue or units sold. The DAG would be Z â†’ T and Z â†’ Y (Z influences both the decision to follow and the outcome), and T â†’ Y (following the recommendation affects the outcome). Unmeasured factors could also affect both T and Y, which is the crux of selection bias. Using DML, they estimate the <strong>propensity</strong> P(T|Z) and the outcome function E(Y|T,Z). Then they compute the causal effect by adjusting Y for differences in propensity (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=At%20this%20year%E2%80%99s%20meeting%20of,the%20effects%20of%20FBA%20recommendations">Removing selection bias from evaluation of recommendations - Amazon Science</a>). In practice, this might involve estimating the <strong>CATE</strong> (conditional average treatment effect) for different sellers.</p> <p><strong>Benefits:</strong> By applying this SCM-based adjustment, Amazon can <strong>filter out selection bias</strong> and get closer to the true causal impact of their recommendations (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=seller%20populations%2C%20those%20who%20follow,not%20follow%20the%20same%20recommendation">Removing selection bias from evaluation of recommendations - Amazon Science</a>). This helped them answer â€œWhat would seller Aâ€™s sales have been if they <em>had not</em> followed the advice?â€ vs. â€œif they did?â€, which is a counterfactual question at the heart of SCMs. The result is used to justify and refine the recommendation service. Notably, Amazon presented this work at an INFORMS conference as a tutorial on cutting-edge causal ML in business (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=same%20recommendation">Removing selection bias from evaluation of recommendations - Amazon Science</a>), signaling the practical importance. The <strong>SCM provided actionable insight</strong>: if the effect is big and positive, Amazon can encourage more sellers to follow recommendations (or even consider incentivizing it); if itâ€™s zero, perhaps the recommendations need improvement.</p> <p><strong>Limitations:</strong> This approach assumes they have captured all important confounders in Z. If some sellers follow recommendations due to an unobserved reason that also boosts sales (e.g. an entrepreneurial mindset), the bias isnâ€™t fully removed. Double ML is powerful (itâ€™s double-robust statistically), but in practice one must ensure the ML models are well-specified and not extrapolating. Another limitation is complexity â€“ Amazon had to deploy an advanced methodology not easily understood outside experts, which is why they are sharing it via conferences. Nonetheless, itâ€™s a case where <strong>observational causal inference was necessary</strong> (they canâ€™t force sellers randomly to ignore beneficial recommendations), and the SCM approach gave Amazon a principled answer (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=seller%20populations%2C%20those%20who%20follow,not%20follow%20the%20same%20recommendation">Removing selection bias from evaluation of recommendations - Amazon Science</a>) (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=to%20use%20cutting,the%20effects%20of%20FBA%20recommendations">Removing selection bias from evaluation of recommendations - Amazon Science</a>).</p> </li> <li> <p><strong>Root Cause Analysis of Business Metrics (AWS):</strong> On AWS, Amazon has developed tools to help customers with <strong>automated root cause analysis</strong> for anomalies using SCMs. For example, consider an online store where profit suddenly drops â€“ many factors could be responsible (traffic, pricing, costs, conversion rate, etc.). AWS researchers leveraged the open-source <strong>DoWhy</strong> library to perform causal graph-based root cause analysis (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=This%20is%20the%20idea%20behind,art%20and%20makes%20it%20available">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>). They contributed new algorithms to DoWhy that can identify the most likely causal drivers of a change in an outcome (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=This%20is%20the%20idea%20behind,art%20and%20makes%20it%20available">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>). The method involves defining a DAG of the relevant metrics (for instance, Page Views â†’ Units Sold â†’ Revenue â†’ Profit, with Unit Price and Cost also affecting Profit). Given an observed shift (profit down), DoWhy can compute measures like <strong>intrinsic causal influence</strong> or <strong>distribution change attribution</strong> for each node in the graph (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=Conclusion">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>) (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=With%20the%20help%20of%20DoWhy%E2%80%99s,a%20shift%20in%20the%20distribution">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>). Essentially, it asks: â€œwhich parent node of Profit changed in a way that could explain the drop, when propagating through the causal model?â€</p> <p>(<a href=https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/ >Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>) <em>Example output of an SCM-based root cause analysis (from an AWS case study). The chart attributes a drop in Profit to changes in Page Views primarily (large negative bar), whereas Unit Price had a positive effect, etc. Such analyses help pinpoint which metricsâ€™ shifts <strong>caused</strong> the outcome change (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=going%20on%20there,now%20start%20mitigating%20the%20issue">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>) (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=With%20the%20help%20of%20DoWhy%E2%80%99s,a%20shift%20in%20the%20distribution">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>).</em></p> <p><strong>Problem:</strong> Quickly diagnose <strong>why</strong> a key metric (KPI) changed, in a complex system with many interacting metrics. This is critical for businesses to take the right action (e.g. if profit fell due to traffic loss vs. due to increased costs, the responses differ).</p> <p><strong>Approach:</strong> Model the relationships between metrics in a causal DAG. In our example, the DAG might be: Ad Spend â†’ Page Views â†’ Sold Units â†’ Revenue â†’ Profit (a funnel), plus Unit Price â†’ Revenue and Operational Cost â†’ Profit as additional influences. AWSâ€™s solution builds a Bayesian network (a probabilistic SCM) of these factors (<a href="https://aws.amazon.com/blogs/machine-learning/generate-a-counterfactual-analysis-of-corn-response-to-nitrogen-with-amazon-sagemaker-jumpstart-solutions/#:~:text=This%20solution%20proposes%20a%20causal,application%20and%20the%20corn%20yields">Generate a counterfactual analysis of corn response to nitrogen with Amazon SageMaker JumpStart solutions | AWS Machine Learning Blog</a>), using historical data to estimate relationships. When a profit drop is observed, they perform a <em>counterfactual analysis</em>: â€œHad Page Views not dropped, what would Profit be?â€ (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=going%20on%20there,now%20start%20mitigating%20the%20issue">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>). By doing this for each candidate cause, they quantify each factorâ€™s responsibility. The DoWhy library provides functions to compute these attributions (like <em>causal effect of change in X on Y</em>). According to AWS, their new DoWhy features allowed them to <strong>pinpoint main drivers with just a few lines of code</strong> (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=With%20the%20help%20of%20DoWhy%E2%80%99s,a%20shift%20in%20the%20distribution">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>), making it very usable for analysts.</p> <p><strong>Benefits:</strong> This SCM approach is essentially <strong>automating detective work</strong> that an analyst might do manually. It provides an explanation, not just detection, of an anomaly. In their blog demo, AWS showed how a ~14% drop in Page Views was identified as the primary cause of the profit decline, after ruling out other factors (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=Indeed%2C%20the%20number%20of%20Page,now%20start%20mitigating%20the%20issue">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>). Knowing the root cause (perhaps a site traffic issue) enables the business to take targeted action (fix marketing or check for site issues) rather than, say, wrongly blaming pricing. The advantage of SCM here is its ability to consider the causal structure â€“ e.g. distinguishing whether profit fell because conversion rate dropped versus less traffic at the top â€“ which simple correlational analysis might confuse. It also encourages businesses to <strong>document their assumptions</strong> in a DAG, which improves reasoning and communication.</p> <p><strong>Tools &amp; Example:</strong> AWSâ€™s work led to integrating these capabilities into the open-source <strong>PyWhy</strong> ecosystem (a collaboration between AWS, Microsoft, and others). With DoWhy (part of PyWhy), a user can do something like:</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>dowhy.api</span>  <span class=c1># high-level API</span>
<span class=c1># Assume df is a DataFrame with columns for Profit, PageViews, UnitPrice, etc.</span>
<span class=c1># and graph_str is a string defining the causal graph structure.</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>dowhy</span><span class=o>.</span><span class=n>CausalModel</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>df</span><span class=p>,</span> <span class=n>treatment</span><span class=o>=</span><span class=s2>&quot;PageViews&quot;</span><span class=p>,</span> <span class=n>outcome</span><span class=o>=</span><span class=s2>&quot;Profit&quot;</span><span class=p>,</span> <span class=n>common_causes</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;AdSpend&quot;</span><span class=p>,</span><span class=s2>&quot;UnitPrice&quot;</span><span class=p>,</span><span class=s2>&quot;OperationalCost&quot;</span><span class=p>],</span> <span class=n>graph</span><span class=o>=</span><span class=n>graph_str</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>identify_effect</span><span class=p>()</span>
<span class=n>result</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>causal_effect</span><span class=p>()</span>  <span class=c1># hypothetically computes effect of PageViews on Profit</span>
</code></pre></div> <p>In reality, the new features use distribution change attribution: one can call functions to get the impact of changes in each node. The AWS blog showed a bar chart output (like the image above) where each variableâ€™s contribution to Profit change is listed (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=Image%3A%20Root%20cause%20analysis%20chart,Page%20Views%20with%20the%20previous">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>) (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=With%20the%20help%20of%20DoWhy%E2%80%99s,a%20shift%20in%20the%20distribution">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>). The key takeaway is that <strong>such causal analysis can be done with only a few lines of code using DoWhyâ€™s API</strong>, making it feasible to embed in business intelligence pipelines (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=With%20the%20help%20of%20DoWhy%E2%80%99s,a%20shift%20in%20the%20distribution">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>).</p> <p><strong>Limitations:</strong> A limitation is that you must accurately specify the causal graph â€“ if the DAG is wrong (missing a link or having a wrong direction), the conclusions might be wrong. For instance, if one omitted an important cause of both Page Views and Profit (say a seasonal effect or a promotion), the method might misattribute the cause. AWSâ€™s approach suggests using expert knowledge to augment the SCM (<a href="https://www.amazon.science/publications/causal-inference-through-structural-causal-marginal-problem#:~:text=statistical%20marginal%20problem%3A%20given%20a,statistical%20one%20via%20additional%20data">Causal inference through structural causal marginal problem - Amazon Science</a>), which highlights that <strong>SCM is not fully automated â€“ it requires human insight into the systemâ€™s structure</strong>. Moreover, in very high-dimensional systems, enumerating all relevant factors can be challenging. Despite these, the ability to integrate human knowledge (via DAGs) with data is a strength: it makes assumptions transparent and the analysis <strong>auditable</strong> (one can debate â€œdo we believe X causes Y in this way?â€).</p> </li> </ul> <h3 id=other-industry-examples-and-tools>Other Industry Examples and Tools<a class=headerlink href=#other-industry-examples-and-tools title="Permanent link">âš‘</a></h3> <p>Beyond Google, Meta, and Amazon, many other tech companies employ SCMs:</p> <ul> <li> <p><strong>Uber:</strong> At Uber, causal inference is used to improve user experience and operational decision-making. Uber built and open-sourced <strong>CausalML</strong>, a Python library for uplift modeling and heterogeneous treatment effect estimation (<a href="https://causalml.readthedocs.io/en/latest/about.html#:~:text=,assumptions%20on%20the%20model%20form">About CausalML â€” causalml documentation</a>). This library provides methods to estimate individual-level causal effects (CATE) from either experimental or observational data (<a href="https://causalml.readthedocs.io/en/latest/about.html#:~:text=,assumptions%20on%20the%20model%20form">About CausalML â€” causalml documentation</a>). Uberâ€™s teams use these techniques for things like <strong>campaign targeting optimization</strong> â€“ figuring out which riders or drivers would respond positively to a promotion or change (<a href="https://causalml.readthedocs.io/en/latest/about.html#:~:text=Example%20Use%20Cases%EF%83%81">About CausalML â€” causalml documentation</a>). By using SCM-based uplift models, they can target only the users who are causally likely to benefit, thus improving ROI. For example, Uber might model the causal effect of sending a coupon on a riderâ€™s trips in the next month, controlling for rider characteristics; CausalML can estimate that effect for each rider, enabling personalized marketing (<a href="https://causalml.readthedocs.io/en/latest/about.html#:~:text=,experiment%20or%20historical%20observational%20data">About CausalML â€” causalml documentation</a>). This goes beyond correlation by distinguishing true causal uplift from random noise. Internally, Uber applied causal methods to analyze product features as well â€“ e.g. to determine if a new app feature actually caused increased engagement or if active users just happened to adopt it. As one Uber blog noted, <em>â€œTeams across Uber apply causal inference methods... to bring richer insights to operations analysis, product development, and other areas critical to improving the user experienceâ€</em> (<a href="http://econometricsense.blogspot.com/2020/05/the-value-of-business-experiments-part.html#:~:text=,One%20of%20the%20most%20exciting">Econometric Sense: Experimentation and Causal Inference: Strategy and Innovation</a>). This underscores that whether itâ€™s matching supply and demand, pricing strategies, or app design, SCMs help Uber make decisions based on <strong>causal impact rather than intuition or purely predictive models</strong>.</p> </li> <li> <p><strong>Microsoft:</strong> Microsoft has contributed significantly to practical causal inference, both in research and open source. They have used SCMs in contexts like Bing search ads and Office product analytics. A recent Microsoft research example addressed <strong>interference in Bingâ€™s sponsored search ads</strong> â€“ similar to Facebookâ€™s problem but in the search auction setting. Here, multiple ads on a page can affect each other (the presence of one ad can alter click probability on another). Microsoft researchers formulated a causal model of ad <strong>allocational interference</strong>, explicitly modeling how the layout (which ads get shown together) influences user clicks (<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9253562/#:~:text=advertising%2C%20where%20the%20likelihood%20of,the%20utility%20of%20our%20formalization"> Causal Inference in the Presence of Interference in Sponsored Search Advertising - PMC </a>). They used the <strong>language of causal inference with interference</strong> to quantify these interactions and ran experiments on Bingâ€™s ad system to validate the model (<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9253562/#:~:text=the%20individual%20ad,of%20the%20Bing%20search%20engine"> Causal Inference in the Presence of Interference in Sponsored Search Advertising - PMC </a>). The outcome was a better understanding of how ad position and neighbors causally affect performance, allowing Bing to improve auction and ranking algorithms for optimal overall outcomes.</p> </li> </ul> <p>On the tools side, Microsoft has developed <strong>EconML</strong> (for causal effect estimation with machine learning) and was a key player (with AWS) in creating <strong>PyWhy</strong> and DoWhy (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=This%20is%20the%20idea%20behind,art%20and%20makes%20it%20available">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>). These tools are actively used in the industry. For instance, Microsoftâ€™s Office and Windows teams have huge telemetry data; to decide whether a change (like a new UI element) really causes better user retention, they combine A/B tests with causal models to generalize across different user segments. They might use EconMLâ€™s Double Robust Learner or Causal Forests to estimate the effect of a feature toggle on engagement, controlling for user traits. The <strong>advantage</strong> is finding nuanced insights (e.g. feature X helps casual users but not power users) which inform rollout strategies. The <strong>limitation</strong> is that one must have either random variation or strong assumptions â€“ Microsoft often leverages the scale of user data to find natural experiments or uses instrument variables (another causal technique) when pure A/B isnâ€™t possible.</p> <ul> <li><strong>Netflix and Others:</strong> While not explicitly in the question, itâ€™s worth noting that companies like Netflix, LinkedIn, and Airbnb also use SCMs. Netflix has to understand causal effects of recommender system changes on user retention (beyond what A/B can show, since long-term and network effects might exist). LinkedIn has published about <strong>causal embeddings</strong> for recommendations, integrating causal objectives into representation learning (to recommend people/jobs that <em>cause</em> higher engagement, not just correlate). Airbnbâ€™s data science team uses causal inference to evaluate policy changes on two-sided marketplaces (e.g. how does a change in cancellation policy causally impact bookings vs. just correlating with different hosts?). In all cases, the common theme is forming a <strong>structural model of the system</strong> â€“ identifying key variables and mapping out cause-effect relationships â€“ and then applying either algorithms or experiments (or both) to estimate the causal effects.</li> </ul> <h3 id=benefits-of-scm-based-causal-inference>Benefits of SCM-Based Causal Inference<a class=headerlink href=#benefits-of-scm-based-causal-inference title="Permanent link">âš‘</a></h3> <p>Across these examples, several <strong>concrete benefits</strong> of using SCMs in industry emerge:</p> <ul> <li> <p><strong>Answers â€œWhat-ifâ€ Questions:</strong> SCMs allow companies to ask counterfactual questions like <em>â€œWhat if we had not launched this feature?â€</em> or <em>â€œWhat if we increase price by 5%?â€</em> and get quantitative answers. This is crucial for strategy and policy decisions. For instance, Googleâ€™s CausalImpact answered what web traffic would have been without an ad campaign (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=An%20important%20problem%20in%20econometrics,differences">Inferring causal impact using Bayesian structural time-series models</a>), and Amazonâ€™s seller analysis answered what sellersâ€™ sales would be without using FBA recommendations (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=The%20goal%20of%20these%20recommendations,from%20not%20aligning%20with%20them">Removing selection bias from evaluation of recommendations - Amazon Science</a>) (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=seller%20populations%2C%20those%20who%20follow,not%20follow%20the%20same%20recommendation">Removing selection bias from evaluation of recommendations - Amazon Science</a>). Traditional ML focused on prediction cannot do this, because it only learns correlations from existing data. As Facebookâ€™s team noted, <strong>causal inference tackles the â€œdoingâ€ part rather than just the â€œseeingâ€</strong> (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=People%20at%20Facebook%20seem%20to,%E2%80%9Cdifference%20between%20seeing%20and%20doing%E2%80%9D">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>) (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=But%20the%20seeing%20part%20is,we%20might%20not%20see%20an">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>) â€“ this difference means insights from SCMs are directly actionable. Businesses can confidently take actions (or not take them) based on these what-if analyses.</p> </li> <li> <p><strong>Optimization and Personalization:</strong> By understanding causal relationships, companies can <strong>optimize decisions</strong> more effectively. Metaâ€™s marketing mix optimization is a great example â€“ knowing the true causal ROI of each channel lets them reallocate budgets optimally, potentially saving millions. Uberâ€™s uplift modeling allows targeting only the users who will be causally influenced by a promotion (<a href="https://causalml.readthedocs.io/en/latest/about.html#:~:text=,experiment%20or%20historical%20observational%20data">About CausalML â€” causalml documentation</a>), which improves marketing efficiency and customer experience (people not influenced arenâ€™t spammed unnecessarily). In operations, knowing causal drivers helps to prioritize: e.g., if an SCM shows delivery time delays are caused mostly by route inefficiencies vs. package volume, an e-commerce company can invest in route planning algorithms. In summary, <strong>SCM turns data into decisions</strong> by focusing on causal leverage points.</p> </li> <li> <p><strong>Domain Knowledge Integration:</strong> SCMs force teams to make their assumptions explicit by drawing DAGs or writing structural equations. This process itself is valuable â€“ it brings together experts to agree on how they believe the system works (e.g. â€œwe think ad spend affects brand searches which then affect salesâ€). This yields a <strong>shared mental model</strong> of the product or business. Unlike pure machine learning, which can be a black box, SCMs provide a transparent framework where you can incorporate prior knowledge (Google did this with Bayesian priors in CausalImpact (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=schemes%2C%20state,The%20CausalImpact">Inferring causal impact using Bayesian structural time-series models</a>)). It also facilitates <strong>communication</strong>: decision-makers can see a causal diagram and understand the factors involved, and analysts can more clearly explain <em>why</em> something had an effect.</p> </li> <li> <p><strong>Robustness and Generalization:</strong> A well-specified SCM can be more robust to changes than a predictive model. For example, if a model captures that â€œX causes Yâ€, that might hold even as external conditions change (causal mechanisms tend to be more invariant), whereas a correlation might break if environment shifts. Tech companies care about <strong>generalizability</strong> â€“ Facebook explicitly listed it as a focus (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=,observational%20data%2C%20and%20to%20generalizability">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>). They want models that not only fit historical data but also <strong>predict the effect of novel actions</strong>. SCM-based methods (like invariant prediction, causal transfer learning) help ensure that insights remain valid when scaling up or porting to new contexts. Also, SCMs can help with <strong>bias correction</strong>: e.g., eliminating biased associations in algorithmic fairness by modeling true causal factors. In summary, reasoning causally helps AI systems avoid being misled by spurious correlations when conditions change.</p> </li> <li> <p><strong>Diagnostics and Explainability:</strong> As seen with AWSâ€™s root cause analysis, SCMs excel at diagnosing why something happened. This is a form of explainable AI â€“ instead of just detecting a pattern, the causal model can explain it (e.g., â€œMetric X dropped because its parent metric Y droppedâ€). This is valuable for troubleshooting issues in complex software systems (many large-scale outages or revenue drops are investigated with causal analysis of logs and metrics). Moreover, SCMs naturally provide <strong>counterfactual explanations</strong>: â€œthe algorithm recommended this because of factors A, B, C â€“ if A had been different, the outcome would change by D.â€ Big tech companies working on AI fairness and transparency use SCMs to generate such explanations and to test interventions for fairness (by simulating the removal of sensitive attributesâ€™ influence via a causal graph).</p> </li> </ul> <h3 id=challenges-and-limitations>Challenges and Limitations<a class=headerlink href=#challenges-and-limitations title="Permanent link">âš‘</a></h3> <p>Despite the benefits, practitioners must be aware of the <strong>limitations of SCM-based inference</strong>:</p> <ul> <li> <p><strong>Need for Correct Model Specification:</strong> Perhaps the biggest challenge is that <strong>if the causal graph is wrong or important confounders are missing, the conclusions will be wrong</strong>. No statistical method can fully overcome bad assumptions. The Facebook ads study highlights this â€“ even with hundreds of covariates, some unobserved factors made observational estimates deviate greatly from truth (<a href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf#:~:text=Generally%2C%20the%20observational%20methods%20overestimate,our%20paper%2C%20namely%2C%20to%20shed"></a>). This is why companies like Facebook and Amazon still invest heavily in randomized experiments as a gold standard check. SCMs in practice often require sensitivity analyses (e.g. â€œif there were an unknown confounder, how strong would it have to be to change our result?â€) to assess how fragile the conclusions are.</p> </li> <li> <p><strong>Data and Instrumentation Requirements:</strong> Building a reliable SCM often requires <strong>a lot of data and the right kind of data</strong>. For instance, to control for confounding, you may need to log user demographics, behavior history, contextual info, etc. Big tech firms have an advantage here due to abundant data, but even they can fall short (as seen, more data didnâ€™t fully solve bias in ad measurement (<a href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf#:~:text=as%20is%20thought%20in%20the,including%20advertising%2C%20pricing%2C%20promotions%2C%20and"></a>)). In some cases, instruments or proxies are needed â€“ these are hard to find. Also, measuring long-term or system-wide effects (like network effects) may require collecting new kinds of data (e.g. social graph snapshots over time). In summary, <strong>SCM can be data-hungry</strong>, and obtaining all relevant variables is non-trivial.</p> </li> <li> <p><strong>Computational Complexity:</strong> Inferring causal effects with complex models (especially with many variables or large networks) can be computationally expensive. Techniques like MCMC (used in Googleâ€™s CausalImpact (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=lift%20in%20web%20searches%2C%20product,Monte%20Carlo%20algorithm%20for%20model">Inferring causal impact using Bayesian structural time-series models</a>)) or causal discovery algorithms can take significant time. Tech companies mitigate this with their large compute resources and by simplifying models when possible. Still, if an SCM becomes too complex, it might not be tractable to estimate or too slow to use in real-time decisions. This is an area of active research (e.g. <strong>deep learning meets SCM</strong> to handle high-dimensional data more efficiently (<a href="https://link.springer.com/article/10.1007/s10462-024-10886-0#:~:text=A%20survey%20of%20deep%20causal,core%20contributions%20are%20as%20follows">A survey of deep causal models and their industrial applications</a>)).</p> </li> <li> <p><strong>Interpreting Causal Estimates:</strong> Another practical issue is <strong>making causal findings understandable to decision-makers</strong>. While SCMs produce estimates with confidence intervals, stakeholders might ask â€œcan we really trust this?â€ It takes education to build trust in these methods. Many organizations are still more comfortable with A/B tests (because of their conceptual simplicity and concreteness) and may view causal model outputs with skepticism. Big tech companies address this by demonstrating SCM successes (like the examples above) and by combining causal inference with experiments (for validation). Over time, as these methods become more standard (with tools like DoWhy, CausalML, etc.), confidence in their results is growing.</p> </li> <li> <p><strong>Ethical and Policy Constraints:</strong> Sometimes the limitation is not technical but <strong>ethical</strong> â€“ you cannot always do an experiment (forcing or denying a treatment), so you resort to SCM, but that SCM might rely on assumptions that canâ€™t be verified. For example, to evaluate a new healthcare featureâ€™s impact, a company might not ethically withhold it from some users, so they use observational causal inference which has more uncertainty. Companies must be cautious in such cases, perhaps using SCM findings as supportive evidence rather than sole proof.</p> </li> </ul> <p>Despite these challenges, the trend in big tech is clear: <strong>causal thinking is becoming integral to data science</strong>. As one LinkedIn article put it, â€œcausal inference can never replace A/B testingâ€¦ but itâ€™s a critical complementâ€ (<a href="https://devblog.pytorchlightning.ai/3-pytorch-lightning-community-causal-inference-examples-to-inspire-your-next-project-da6f45c07b70#:~:text=Glocker,for%20Tractable%20Counterfactual%20Inference">3 PyTorch Lightning Community Causal Inference Examples To ...</a>). SCMs augment the experimentation toolkit and enable <strong>causal insights at scale</strong> where experiments canâ€™t cover. With open-source libraries (CausalImpact in R, DoWhy/PyWhy, EconML, CausalML in Python) and increasing adoption, even practitioners outside of the tech giants can apply these methods.</p> <h3 id=conclusion>Conclusion<a class=headerlink href=#conclusion title="Permanent link">âš‘</a></h3> <p>In summary, Structural Causal Models have moved from academic theory (thanks to pioneers like Judea Pearl) into the daily practice of big tech companies. Google uses SCMs to measure the true impact of ads and product changes (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=An%20important%20problem%20in%20econometrics,infer%20the%20temporal%20evolution">Inferring causal impact using Bayesian structural time-series models</a>). Meta leverages them for marketing attribution (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=Robyn%2C%20developed%20by%20Meta%20Platforms%2C,so%20on%20besides%20the%20above">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>), experiment design in social networks (<a href="https://dl.acm.org/doi/fullHtml/10.1145/3442381.3449845#:~:text=Causal%20Network%20Motifs%3A%20Identifying%20Heterogeneous,networks%3B%20and%20then%20we">Causal Network Motifs: Identifying Heterogeneous Spillover Effects ...</a>), and to improve their algorithms by focusing on causation over correlation (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=People%20at%20Facebook%20seem%20to,%E2%80%9Cdifference%20between%20seeing%20and%20doing%E2%80%9D">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>). Amazon deploys SCM-based analysis to advise sellers and diagnose business metric changes (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=same%20recommendation">Removing selection bias from evaluation of recommendations - Amazon Science</a>) (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=With%20the%20help%20of%20DoWhy%E2%80%99s,a%20shift%20in%20the%20distribution">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>). Companies like Uber and Microsoft invest in open-source tools to democratize these methods (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=This%20is%20the%20idea%20behind,art%20and%20makes%20it%20available">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>) (<a href="https://causalml.readthedocs.io/en/latest/about.html#:~:text=,assumptions%20on%20the%20model%20form">About CausalML â€” causalml documentation</a>).</p> <p>SCMs offer a <strong>practical, concrete advantage</strong> in industry: they turn passive data into active decisions by answering â€œwhy did this happen?â€ and â€œwhat if we do this?â€ â€“ questions at the core of business strategy. The cases above show that when applied thoughtfully, SCMs can save money (optimizing marketing spend), improve products (by understanding feature effects), and even save time (automating root cause analysis). The key is to combine domain knowledge with data, use experiments to support/validate when possible, and remain aware of the assumptions. As tools and experience grow, we can expect even broader adoption of SCMs in tech and beyond, enabling more <strong>cause-driven innovation</strong> rather than just correlation-driven guesswork.</p> <p><strong>Sources:</strong></p> <ul> <li>Googleâ€™s Bayesian structural time-series model for ad impact (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=An%20important%20problem%20in%20econometrics,infer%20the%20temporal%20evolution">Inferring causal impact using Bayesian structural time-series models</a>) (<a href="https://research.google/pubs/inferring-causal-impact-using-bayesian-structural-time-series-models/#:~:text=schemes%2C%20state,The%20CausalImpact">Inferring causal impact using Bayesian structural time-series models</a>)</li> <li>Metaâ€™s open-source <em>Robyn</em> MMM tool and causal structure considerations (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=Robyn%2C%20developed%20by%20Meta%20Platforms%2C,so%20on%20besides%20the%20above">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>) (<a href="https://medium.com/@tanakaryo/consider-the-causal-structure-in-marketing-mix-modeling-with-robyn-fe889cad4598#:~:text=practical%20case%2C%20each%20ad%20has,endogeneity%20from%20a%20theoretical%20point">Consider the causal structure in Marketing Mix Modeling with Robyn | by Ryo Tanaka | Medium</a>)</li> <li>Facebookâ€™s causal inference team focus and network spillover research (<a href="https://p-hunermund.com/2018/04/27/facebooks-causal-inference-group/#:~:text=,observational%20data%2C%20and%20to%20generalizability">Facebookâ€™s Causal Inference Group â€“ Paul HÃ¼nermund, Ph.D.</a>) (<a href="https://dl.acm.org/doi/fullHtml/10.1145/3442381.3449845#:~:text=Causal%20Network%20Motifs%3A%20Identifying%20Heterogeneous,networks%3B%20and%20then%20we">Causal Network Motifs: Identifying Heterogeneous Spillover Effects ...</a>)</li> <li>Facebook experiment vs. observational ad measurement study (limitations of SCM) (<a href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/fb_comparison.pdf#:~:text=An%20analysis%20of%20our%2015,a%20factor%20of%20three%20across"></a>)</li> <li>Amazon Science: Causal ML for FBA seller recommendations (double ML approach) (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=seller%20populations%2C%20those%20who%20follow,not%20follow%20the%20same%20recommendation">Removing selection bias from evaluation of recommendations - Amazon Science</a>) (<a href="https://www.amazon.science/blog/removing-selection-bias-from-evaluation-of-recommendations#:~:text=to%20use%20cutting,the%20effects%20of%20FBA%20recommendations">Removing selection bias from evaluation of recommendations - Amazon Science</a>)</li> <li>AWS blog on causal root cause analysis with DoWhy (causal DAG for profit drop) (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=With%20the%20help%20of%20DoWhy%E2%80%99s,a%20shift%20in%20the%20distribution">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>) (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=Conclusion">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>)</li> <li>Uberâ€™s CausalML library and use cases (uplift modeling for targeting) (<a href="https://causalml.readthedocs.io/en/latest/about.html#:~:text=,experiment%20or%20historical%20observational%20data">About CausalML â€” causalml documentation</a>) (<a href="http://econometricsense.blogspot.com/2020/05/the-value-of-business-experiments-part.html#:~:text=,One%20of%20the%20most%20exciting">Econometric Sense: Experimentation and Causal Inference: Strategy and Innovation</a>)</li> <li>Microsoft research on ad interference (Bing ads causal modeling) (<a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9253562/#:~:text=advertising%2C%20where%20the%20likelihood%20of,the%20utility%20of%20our%20formalization"> Causal Inference in the Presence of Interference in Sponsored Search Advertising - PMC </a>) and contributions to PyWhy/DoWhy (<a href="https://aws.amazon.com/blogs/opensource/root-cause-analysis-with-dowhy-an-open-source-python-library-for-causal-machine-learning/#:~:text=This%20is%20the%20idea%20behind,art%20and%20makes%20it%20available">Root Cause Analysis with DoWhy, an Open Source Python Library for Causal Machine Learning | AWS Open Source Blog</a>).</li> </ul> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago" title="May 11, 2025 14:51:30 UTC"><span class=timeago datetime=2025-05-11T14:51:30+00:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date" title="May 11, 2025 14:51:30 UTC">2025-05-11</span> </span> </aside> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../909ed374-e61f-4332-9619-4dedc93439ba/ class="md-footer__link md-footer__link--prev" aria-label="Previous: bayesian-notation"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> bayesian-notation </div> </div> </a> <a href=../e526860c-b2ec-4be4-862e-06cb5188bd07/ class="md-footer__link md-footer__link--next" aria-label="Next: devcontainer"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> devcontainer </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/lyz-code target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 480 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg> </a> <a href=https://lyz-code.github.io/blue-book/newsletter/0_newsletter_index target=_blank rel=noopener title=lyz-code.github.io class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 64c0-17.7 14.3-32 32-32 229.8 0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7 0 64m0 352a64 64 0 1 1 128 0 64 64 0 1 1-128 0m32-256c159.1 0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["navigation.footer", "navigation.top", "content.code.annotate", "search.suggest", "search.highlight"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.13a4f30d.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> <script src=../assets/js/katex.js></script> <script src=https://unpkg.com/katex@0/dist/katex.min.js></script> <script src=https://unpkg.com/katex@0/dist/contrib/auto-render.min.js></script> </body> </html>