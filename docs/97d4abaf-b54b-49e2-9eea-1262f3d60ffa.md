### **1. 필수적으로 살펴봐야 할 지표**

#### **1.1. Latency (지연 시간)**

- **의미**: 요청이 들어온 시점부터 응답을 반환하기까지 걸리는 시간.
- **측정 방식**:
    - API Gateway (예: AWS API Gateway, GCP Cloud Endpoints)의 로그 분석.
    - Application Performance Monitoring (APM) 툴 (예: New Relic, Datadog).
    - 서비스 코드 내에서 타이머로 측정.
- **대응 방법**:
    - **모델 최적화**:
        - ONNX, TensorRT로 모델 변환 및 최적화.
        - FP16 또는 INT8로 모델을 경량화.
    - **배포 최적화**:
        - GPU 또는 고성능 CPU로 inference를 수행.
        - Batch inference를 사용하여 한 번에 여러 요청 처리.
    - **캐싱 사용**:
        - 자주 요청되는 결과를 Redis와 같은 메모리 캐싱 서비스에 저장.

#### **1.2. Throughput**

- **의미**: 초당 처리 가능한 요청 수.
- **측정 방식**:
    - 부하 테스트 툴 (예: Apache JMeter, Locust).
    - 서버의 로그 분석.
- **대응 방법**:
    - **Auto-scaling**: 수요에 따라 서버 인스턴스를 동적으로 확장.
    - **모델 서빙 최적화**: Ray Serve, TensorFlow Serving, Triton Server 등 고성능 서빙 엔진 활용.

#### **1.3. Error Rate**

- **의미**: 요청 중 에러(5xx, 4xx 상태 코드)를 반환한 비율.
- **측정 방식**:
    - API Gateway 또는 Web Server의 로그 분석.
    - APM 도구의 에러 대시보드.
- **대응 방법**:
    - **코드 디버깅**: 에러 로그 분석 후 예외 처리 개선.
    - **서버 상태 확인**: 메모리 부족, 디스크 I/O 병목 등을 확인하고 적절히 확장.

#### **1.4. Resource Utilization**

- **의미**: CPU, GPU, 메모리, 네트워크 사용량.
- **측정 방식**:
    - Prometheus + Grafana를 사용한 리소스 모니터링.
    - 클라우드 제공 서비스 (예: AWS CloudWatch, GCP Monitoring).
- **대응 방법**:
    - **리소스 최적화**:
        - 모델 실행에 필요한 리소스 확인 후 적절한 인스턴스 선택.
        - 병렬 처리 구조 개선.

#### **1.5. Queue Time**

- **의미**: 요청이 처리 대기열에서 기다리는 시간.
- **측정 방식**:
    - APM 도구에서 제공하는 대기열 시간 분석 기능.
- **대응 방법**:
    - 워커 노드 수 증가.
    - 비동기 요청 처리.

#### **1.6. Success Rate**

- **의미**: 요청 중 성공적으로 처리된 비율 (200 상태 코드 반환 비율).
- **측정 방식**:
    - 서버 로그 분석.
- **대응 방법**:
    - 에러 로그를 기반으로 문제를 식별하고 수정.
    - 헬스 체크 및 요청 유효성 검사를 강화.

#### **1.7. Cold Start Latency**

- **의미**: 서버가 처음 요청을 처리할 때 발생하는 초기 지연 시간.
- **측정 방식**:
    - 서버 재시작 후 첫 번째 요청의 응답 시간 측정.
- **대응 방법**:
    - Lambda 사용 시, **Provisioned Concurrency** 설정.
    - 컨테이너 기반 배포 시, 워밍업 작업 추가.

---

### **2. 주요 모니터링 도구 및 방법**

1. **APM 툴**:
    - **New Relic, Datadog**: 애플리케이션의 전반적인 성능 및 에러 모니터링.
2. **로그 분석**:
    - **ELK Stack (ElasticSearch, Logstash, Kibana)**: API 요청 및 응답 데이터 시각화.
3. **메트릭 수집 및 시각화**:
    - **Prometheus + Grafana**: 리소스 사용량 및 API 성능 모니터링.
4. **부하 테스트**:
    - **Locust, JMeter**: 시스템 처리 용량과 한계점 테스트.

---

### **3. 주요 문제들에 대한 대응 방법 요약**

| **문제**             | **대응 방법**                                                            |
|----------------------|--------------------------------------------------------------------------|
| **응답 시간 느림**   | 모델 최적화(TensorRT, ONNX), 캐싱 적용(Redis), 병렬 처리.                |
| **에러 빈도 증가**   | 에러 로그 분석, 적절한 예외 처리 추가.                                   |
| **리소스 과부하**    | 인스턴스 업그레이드, 리소스 스케일링(Auto-scaling).                      |
| **처리량 부족**      | 워커 노드 증설, 배치 처리, 모델 서빙 최적화(Triton, TensorFlow Serving). |
| **콜드 스타트 지연** | 서버 워밍업, Provisioned Concurrency 설정.                               |
| **네트워크 병목**    | 로드 밸런싱 설정 최적화, CDN 적용.                                       |

---

### **4. 추가적으로 권장되는 모니터링 방법**

1. **유저 경험 모니터링**:
    - 실제 클라이언트 단에서 느끼는 응답 시간 측정 (RUM, Real User Monitoring).
2. **비즈니스 지표**:
    - 예를 들어, 머신러닝 API가 추천을 제공한다면, 추천 성공률이나 클릭율(CTR) 같은 비즈니스 지표를 모니터링.
