---
publish: true
uuid: 1e3e96b7-2d44-44c5-8987-b1f731d2322a
---

## TL;DR

- 데이터 웨어하우스
    - 목적: 통합된 구조화 데이터 저장 및 분석
    - 처리 방식: ETL 또는 ELT
    - 사용 사례: 복잡한 쿼리, 비즈니스 인텔리전스(BI)
- 데이터 마트
    - 목적: 특정 부서나 주제에 특화된 데이터 저장
    - 처리 방식: 데이터 웨어하우스에서 추출한 데이터 사용
    - 사용 사례: 부서별 맞춤형 데이터 분석
- 데이터 레이크
    - 목적: 원시 상태의 대규모 데이터 저장
    - 처리 방식: ELT, Schema-on-Read
    - 사용 사례: 빅 데이터 분석, 머신 러닝

## 데이터 웨어하우스, 데이터 마트, 데이터 레이크의 차이점

- **데이터 웨어하우스**: 조직의 다양한 출처에서 데이터를 통합하여 구조화된 형태로 저장하고, 주로 분석 및 보고 목적으로 사용함. ETL 방식을 통해 데이터를 정제하고 변환하여 로드함.
- **데이터 마트**: 데이터 웨어하우스의 하위 집합으로, 특정 부서나 비즈니스 라인의 요구에 맞춰 데이터를 저장함. 특정 주제나 부서에 특화된 데이터 구조를 가짐.
- **데이터 레이크**: 다양한 형식의 데이터를 원시 상태로 대량 저장할 수 있는 시스템임. 주로 비구조적 데이터를 포함하며, ELT 방식을 사용해 데이터를 로드한 후 필요할 때 변환함.

## AWS를 활용한 구현 방법

- **데이터 웨어하우스**: Amazon Redshift를 중심으로 구현함. 데이터를 통합하고 분석할 수 있는 강력한 기능을 제공함.
- **데이터 마트**: Amazon Redshift의 일부로 구현되거나, 특정 사용 사례에 따라 Amazon RDS나 DynamoDB를 사용할 수 있음.
- **데이터 레이크**: Amazon S3를 기반으로 하여 다양한 데이터 형식을 저장하고, AWS Glue, Amazon Athena 등을 활용해 데이터 처리 및 분석을 수행함.

<details class="note" markdown="1">
<summary>AWS 구현 세부 정보</summary>

**AWS 데이터 웨어하우스 구현**

- **Amazon Redshift**: 대규모 데이터를 처리할 수 있는 완전 관리형 데이터 웨어하우스 서비스임.
- **구현 과정**:
    - Redshift 클러스터 생성
    - AWS Glue, S3 등을 통해 데이터 수집
    - Glue를 사용해 ETL 작업 수행
    - Amazon QuickSight를 통해 데이터 분석 및 시각화

**AWS 데이터 마트 구현**

- **Amazon Redshift 스펙트럼**: Redshift 내에서 데이터 마트를 구성할 수 있음.
- **구현 과정**:
    - Redshift에서 필요한 데이터 추출
    - 데이터 마트용 스키마 생성
    - ETL 프로세스를 통해 데이터 변환 및 로드
    - 특정 부서용 데이터 접근 권한 설정

**AWS 데이터 레이크 구현**

- **Amazon S3**: 대규모 원시 데이터를 저장할 수 있는 객체 스토리지 서비스임.
- **구현 과정**:
    - S3 버킷 생성
    - Glue, Kinesis, DMS 등을 사용해 데이터 수집
    - Glue Data Catalog를 통해 메타데이터 관리
    - Athena, EMR, SageMaker 등을 활용한 데이터 처리 및 분석

**AWS 통합 아키텍처**

- **데이터 흐름**: 데이터 소스 → S3 (데이터 레이크) → Glue (ETL) → Redshift (데이터 웨어하우스) → 특정 스키마/테이블 (데이터 마트)
- **통합 사용**: 각 계층에서 QuickSight, Athena 등을 사용해 데이터 분석 및 시각화를 수행함.

</details>

## GCP를 활용한 구현 방법

- **데이터 웨어하우스**: Google BigQuery를 사용하여 대규모 데이터를 빠르고 효율적으로 분석할 수 있음. BigQuery는 완전 관리형 서버리스 데이터 웨어하우스로, 실시간 분석과 복잡한 쿼리에 최적화되어 있음.
- **데이터 마트**: BigQuery의 데이터셋 기능을 활용하거나, 특정 사용 사례에 따라 Google Cloud SQL 또는 Cloud Spanner를 사용할 수 있음. 이들 서비스는 관계형 데이터베이스로, 부서별로 특화된 데이터 분석이 가능함.
- **데이터 레이크**: Google Cloud Storage(GCS)를 기반으로 데이터 레이크를 구축함. 다양한 형식의 데이터를 원시 형태로 저장하고, Google Cloud Dataproc을 사용해 데이터 처리와 분석을 수행하며, Google Dataflow를 통해 실시간 데이터 처리도 가능함.

<details class="note" markdown="1">
<summary>GCP 구현 세부정보</summary>

## GCP 데이터 웨어하우스 구현

- **BigQuery**: 페타바이트 규모의 데이터를 처리할 수 있는 서버리스, 고확장성 데이터 웨어하우스임.
- **구현 과정**:
    - BigQuery 프로젝트 및 데이터셋 생성
    - Cloud Storage, Cloud Dataflow 등을 통해 데이터 로드
    - Cloud Dataflow 또는 Cloud Dataprep을 사용해 ETL 작업 수행
    - Data Studio 등을 통해 데이터 분석 및 시각화

## GCP 데이터 마트 구현

- **BigQuery**: 특정 데이터셋이나 뷰를 데이터 마트로 구성함.
- **구현 과정**:
    - BigQuery에서 필요한 데이터 추출
    - 데이터 마트용 데이터셋 또는 테이블 생성
    - ETL 프로세스를 통해 데이터 변환 및 로드
    - 특정 부서나 팀을 위한 액세스 권한 설정

## GCP 데이터 레이크 구현

- **Cloud Storage**: 대규모 원시 데이터를 저장할 수 있는 객체 스토리지 서비스임.
- **구현 과정**:
    - Cloud Storage 버킷 생성
    - Cloud Dataflow, Pub/Sub 등을 사용해 데이터 수집
    - Cloud Data Catalog를 통해 메타데이터 관리
    - Dataproc, BigQuery, AI Platform 등을 활용해 데이터 처리 및 분석

## GCP 통합 아키텍처 및 보안

- **데이터 흐름**: 데이터 소스 → Cloud Storage (데이터 레이크) → Cloud Dataflow (ETL) → BigQuery (데이터 웨어하우스) → 특정 데이터셋/뷰 (데이터 마트)
- **데이터 거버넌스 및 보안**:
    - Cloud IAM을 통한 세분화된 액세스 제어
    - Cloud DLP로 민감한 데이터 식별 및 보호
    - Cloud KMS를 통한 암호화 키 관리
    - VPC Service Controls를 사용해 보안 경계 설정

이러한 아키텍처를 통해 원시 데이터부터 정제된 데이터, 그리고 특정 목적의 데이터까지 효율적으로 관리하고 활용할 수 있음. GCP의 다양한 보안 도구를 통해 데이터의 보안과 규정 준수를 강화할 수 있음.

</details>

## 데이터의 흐름과 통합

- 데이터 레이크 → 데이터 웨어하우스 → 데이터 마트의 순서로 데이터가 흐름. 각 시스템은 서로 통합되어 조직의 데이터 관리 및 분석을 효율적으로 지원함.
- AWS와 GCP의 다양한 서비스를 활용하여 데이터의 수집, 저장, 분석, 시각화를 위한 통합적인 데이터 아키텍처를 구축할 수 있음.
