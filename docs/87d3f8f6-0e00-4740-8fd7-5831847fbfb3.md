## TL; DR

- 객체 검출 모델의 성능을 평가하는 대표적인 지표는 mAP가 있음
- AP는 PR 곡선 아래 면적을 의미하고, 구체적으로 계산하는 방법은 PASCAL VOC와 COCO 평가 방식이 있음
- mAP는 여러 클래스에 대한 AP의 평균을 의미함

## Object Detection의 평가 방식

- PASCAL VOC 평가 방식:
    - 주로 IoU 임계값 0.5에서의 평균 정밀도(AP)를 사용함
    - 포인트 보간법을 사용하여 AP를 계산함
- COCO 평가 방식:
    - 여러 IoU 임계값(0.5에서 0.95까지 0.05 간격)에서의 AP를 평균내어 사용함
    - PR 곡선 전체 영역을 적분하여 AP를 계산함
- KITTI 평가 방식:
    - 자율주행 차량을 위한 객체 검출에 특화된 평가 방식임
    - 3D 바운딩 박스와 2D 바운딩 박스 모두에 대해 평가함
    - 쉬움, 보통, 어려움의 세 가지 난이도로 평가함
- Open Images 평가 방식:
    - 계층적 레이블 구조를 고려한 평가 방식을 사용함
    - 그룹 평균 정밀도(Group-Average Precision)를 사용하여 클래스 간 불균형을 처리함

## IoU 에 따 True Positive, False Positive, False Negative

- IoU 임계값: 예측된 바운딩 박스와 실제 바운딩 박스의 겹치는 정도를 측정하는 임계값
    - 일반적으로 0.5나 0.7과 같은 값을 사용함
    - IoU 임계값이 높을수록 더 엄격한 평가 기준이 됨

- True Positive (TP):
    - 예측된 바운딩 박스와 실제 바운딩 박스가 IoU 임계값 이상으로 겹치는 경우
    - 올바른 클래스로 예측되어야 함
    - 하나의 실제 객체에 대해 가장 높은 IoU를 가진 예측만 TP로 간주됨

- False Positive (FP):
    - 예측된 바운딩 박스가 실제 바운딩 박스와 IoU 임계값 이상으로 겹치지 않는 경우
    - 배경을 객체로 잘못 예측한 경우도 포함됨
    - 동일한 객체에 대해 중복 예측된 경우도 FP로 간주됨

- False Negative (FN):
    - 실제 바운딩 박스가 예측된 바운딩 박스와 IoU 임계값 이상으로 겹치지 않는 경우
    - 모델이 객체를 검출하지 못한 경우를 의미함

- 추가 고려사항:
    - 클래스별 평가: 각 클래스마다 별도로 TP, FP, FN을 계산함
    - 신뢰도 점수: 객체 검출 모델은 각 예측에 대한 신뢰도 점수를 제공하며, 이를 기반으로 정밀도-재현율 곡선을 그릴 수 있음
    - 다중 IoU 임값: COCO 평가 방식처럼 여러 IoU 임계값에 대해 평가를 수행하여 모델의 성능을 더 종합적으로 평가할 수 있음

- True Negative (TN)의 부재:
    - 객체 검출에서는 True Negative를 명시적으로 정의하지 않음
    - 이유:
    1. 배경의 정의: 객체가 없는 모든 영역을 배경으로 간주하면, TN의 수가 무한대에 가까워질 수 있음
    2. 관심 대상: 객체 검출의 주요 목적은 객체를 찾는 것이므로, 배경을 올바르게 식별하는 것은 덜 중요함
    3. 평가 지표: 주로 사용되는 mAP나 정밀도-재현율 곡선은 TN을 필요로 하지 않음
    - 대신 False Positive를 통해 모델이 배경을 객체로 잘못 식별하는 경우를 평가함

- 객체 검출에서의 이진 분류와의 차이:
    - 이진 분류에서는 TP, TN, FP, FN 모두를 사용하지만, 객체 검출은 TP, FP, FN만을 사용함
    - 이로 인해 정확도(Accuracy)와 같은 TN을 포함하는 지표 대신 mAP, F1 점수 등을 주로 사용함

## 지표

- 정밀도(Precision):
    - 예측된 양성 샘플 중 실제 양성 샘플의 비율임
    - 수식: Precision = True Positives / (True Positives + False Positives)
- 재현율(Recall):
    - 실제 양성 샘플 중 예측된 양성 샘플의 비율임
    - 수식: Recall = True Positives / (True Positives + False Negatives)
- 평균 정밀도(Average Precision, AP):
    - 정밀도와 재현율의 곡선 아래 면적임
    - 모든 가능한 재현율 값에 대한 정밀도의 평균임
- IoU (Intersection over Union):
    - 예측된 바운딩 박스와 실제 바운딩 박스의 겹치는 정도를 측정함
    - 수식: IoU = (예측 박스 ∩ 실제 박스) / (예측 박스 ∪ 실제 박스)
- mAP (mean Average Precision):
    - 여러 클래스에 대한 AP의 평균임
    - 객체 탐지 모델의 전체적인 성능을 나타내는 단일 지표임
- F1 점수:
    - 정밀도와 재현율의 조화 평균임
    - 수식: F1 = 2 *(Precision* Recall) / (Precision + Recall)
- FPS (Frames Per Second):
    - 모델의 실시간 처리 능력을 나타내는 지표임
    - 초당 처리할 수 있는 이미지 프레임 수임

## mAP의 계산

1. 포인트 개수의 영향:
    - 포인트 개수가 적으면: 계산은 빠르지만 정확도가 떨어질 수 있음
    - 포인트 개수가 많으면: 더 정확한 결과를 얻을 수 있지만 계산 시간이 늘어남

2. 보간 방법:
    - PASCAL VOC: 11-point 보간법을 사용함. 재현율 0부터 1까지 0.1 간격으로 11개 포인트에서 정밀도를 계산함
    - COCO: 모든 포인트를 사용하여 PR 곡선 전체 영역을 적분함

3. 안정성 개선 방법:
    - 모든 포인트 사용: 가능한 모든 임계값에 대해 정밀도와 재현율을 계산함
    - 정밀도 평활화: 각 재현율 수준에서 해당 재현율 이상의 최대 정밀도를 사용함
    - 보간법 사용: 선형 보간이나 더 복잡한 보간 방법을 사용하여 곡선을 부드럽게 만듦

4. 구현 시 주의사항:
    - 일관성 유지: 평가 시 항상 동일한 방법과 포인트 개수를 사용해야 함
    - 표준 준수: 가능한 PASCAL VOC나 COCO와 같은 표준 평가 방식을 따르는 것이 좋음
    - 충분한 포인트: 정확한 결과를 위해 충분한 수의 포인트를 사용해야 함

5. 라이브러리 활용:
    - pycocotools나 VOC 평가 스크립트와 같은 검증된 라이브러리를 용하면 일관성 있는 결과를 얻을 수 있음

## IoU 에 따른 True Positive, False Positive, False Negative

- True Negative (TN)의 부재:
    - 객체 검출에서는 True Negative를 명시적으로 정의하지 않음
    - 이유:
        - 배경의 정의: 객체가 없는 모든 영역을 배경으로 간주하면, TN의 수가 무한대에 가까워질 수 있음
        - 관심 대상: 객체 검출의 주요 목적은 객체를 찾는 것이므로, 배경을 올바르게 식별하는 것은 덜 중요함
        - 평가 지표: 주로 사용되는 mAP나 정밀도-재현율 곡선은 TN을 필요로 하지 않음
    - 대신 False Positive를 통해 모델이 배경을 객체로 잘못 식별하는 경우를 평가함

- 객체 검출에서의 이진 분류와의 차이:
    - 이진 분류에서는 TP, TN, FP, FN 모두를 사용하지만, 객체 검출은 TP, FP, FN만을 사용함
    - 이로 인해 정확도(Accuracy)와 같은 TN을 포함하는 지표 대신 mAP, F1 점수 등을 주로 사용함
