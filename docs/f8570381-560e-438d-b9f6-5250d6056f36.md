---
publish: true
uuid: f8570381-560e-438d-b9f6-5250d6056f36
---

## TL;DR

- Transform 디자인 패턴은 입력과 특징을 명확히 분리하여 머신러닝 모델을 프로덕션 환경에서 쉽게 적용할 수 있도록 함.
- 훈련과 서빙 환경 간의 일관성을 유지하여 훈련-서빙 스큐 문제를 해결함.
- BigQuery ML의 `TRANSFORM` 절을 활용하면 데이터 변환 로직을 모델에 포함하여 예측 시 자동으로 적용할 수 있음.

## Transform 디자인 패턴 개요

- 머신러닝 모델의 입력은 원시 데이터이며, 학습 시 변환된 특징과 다를 수 있음.
- 훈련 시 적용된 변환이 서빙 중에도 동일하게 유지되어야 함.
- `TRANSFORM` 절을 활용하면 자동 변환이 가능하여 훈련-서빙 스큐를 방지할 수 있음.

## Transform 패턴이 훈련-서빙 스큐를 방지하는 방법

- 모델 학습 시 데이터 전처리를 수행하지만, 서빙 시 동일한 변환이 적용되지 않으면 모델 입력이 다르게 처리될 위험이 있음.
- 예를 들어, 텍스트 분류 모델의 학습 시 토큰화, 정규화 등의 전처리를 수행하지만, 서빙 환경에서 같은 방식으로 적용되지 않으면 성능 저하가 발생함.
- `TRANSFORM` 절을 사용하면 학습 시 정의한 변환 로직이 모델에 포함되며, 예측 시 `ML.PREDICT`를 통해 자동으로 적용됨.

## Transform 디자인 패턴이 내장되지 않은 프레임워크에서의 적용

- Transform 디자인 패턴이 기본적으로 지원되지 않는 프레임워크를 사용할 경우, 훈련 시 수행된 변환이 서빙 시 쉽게 재현될 수 있도록 모델 아키텍처를 설계해야 함.
- 변환 로직을 모델 그래프에 포함하거나, 변환된 특징을 별도의 저장소에 저장하는 방법을 고려해야 함.
- **TensorFlow의 특징 열(Feature Column) 개념**
    - TensorFlow는 기본적으로 원시 입력이 특징과 동일하다고 가정하여 설계됨.
    - `tf.feature_column` API를 활용하여 원시 데이터를 변환하는 전략을 사용할 수 있음.
    - 하지만 `tf.feature_column`은 훈련과 서빙 간 변환 일관성을 자동으로 보장하지 않으므로, 추가적인 관리가 필요함.
- **tf.Transform을 활용한 변환 자동화**
    - `tf.Transform`을 사용하면 훈련 시 수행된 변환을 저장하고 서빙 시 동일한 변환을 자동으로 적용할 수 있음.
    - 데이터 전처리 단계를 모델 학습과 함께 처리하고, 결과적인 변환된 특징과 변환 아티팩트를 저장하여 TensorFlow Serving에서 예측 시간에 자동으로 변환 적용 가능.

## tf.Transform의 출력 아티팩트

`tf.Transform` 컴포넌트는 **두 가지 주요 아티팩트**를 생성함:

1. **변환된 데이터 (Transformed Data)**
    - `preprocessing_fn`을 사용하여 원본 데이터를 변환한 후 저장됨.
    - `TFRecord` 형식으로 저장되며, `Trainer`가 학습할 때 사용됨.
    - 예: `train_transformed.tfrecord`, `eval_transformed.tfrecord`

2. **변환 그래프 (Transform Graph)**
    - `preprocessing_fn`에서 정의된 변환 로직을 **TensorFlow SavedModel 형식의 그래프로 저장**.
    - 서빙 시 새로운 입력 데이터를 변환하는 데 사용됨.
    - `transform_fn` 디렉터리에 저장됨 (예: `transform_fn/saved_model.pb`).

이러한 구조를 통해 학습 및 서빙 환경에서 일관된 데이터 변환을 보장할 수 있음.

### 예제 코드: tf.Transform을 활용한 변환 저장 및 적용

#### 학습 시 변환 적용 및 저장

~~~python
import tensorflow_transform as tft

def preprocessing_fn(inputs):
    outputs = {}
    outputs['normalized_age'] = tft.scale_to_z_score(inputs['age'])
    outputs['hashed_feature'] = tft.compute_and_apply_vocabulary(inputs['feature_column'])
    return outputs
~~~

#### 서빙 시 변환 적용

~~~python
import tensorflow as tf

def apply_saved_transform(raw_data, transform_graph_path):
    # 저장된 변환 그래프 로드
    saved_model = tf.saved_model.load(transform_graph_path)
    # 서빙 함수 호출
    serving_fn = saved_model.signatures['serving_default']
    # 입력 데이터를 변환된 텐서로 변환
    transformed_data = serving_fn(**raw_data)
    return transformed_data
~~~

- `tf.Transform`을 사용하면 훈련과 서빙 환경에서 동일한 변환을 자동으로 적용할 수 있어 훈련-서빙 스큐를 방지할 수 있음.
- 변환된 데이터와 모델 아티팩트를 함께 저장하여 프로덕션 환경에서 변환을 별도로 관리할 필요 없음.

## BigQuery ML에서 Transform 적용

- `TRANSFORM` 절을 사용하여 변환 로직을 모델에 포함할 수 있음.

- 변환된 특징을 저장하고 예측 시 자동 적용됨.

- 학습 예제 코드:

  ~~~sql
  CREATE OR REPLACE MODEL my_dataset.user_behavior_model
  OPTIONS(input_label_cols=['click_rate'], model_type='linear_reg')
  TRANSFORM(
      SELECT * EXCEPT(event_time),
          CAST(EXTRACT(dayofweek FROM event_time) AS STRING) AS dayofweek,
          CAST(EXTRACT(hour FROM event_time) AS STRING) AS hourofday
  )
  AS
  SELECT click_rate, user_id, event_time
  FROM `my_project.user_data.events`;
  ~~~

- 예측 시 변환이 자동으로 적용되는 코드:

  ~~~sql
  SELECT *
  FROM ML.PREDICT(
      MODEL my_dataset.user_behavior_model,
      (SELECT user_id, event_time FROM `my_project.user_data.new_events`)
  );
  ~~~

- `ML.PREDICT`를 사용하면 모델 학습 시 정의된 변환이 자동으로 적용되므로, 예측 시 별도의 변환을 수행할 필요가 없음.

## 마무리

`TRANSFORM` 절을 사용하면 모델 학습 시 정의된 변환이 자동으로 저장되고, `ML.PREDICT` 호출 시 자동으로 적용됨. 이를 통해 훈련과 서빙 환경 간의 일관성을 유지하고, 훈련-서빙 스큐를 방지할 수 있음. TensorFlow 및 `tf.Transform`을 활용하면 동일한 원칙을 적용하여 데이터 전처리를 자동화하고 일관성을 보장할 수 있음.